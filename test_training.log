cuda
Split dir: splits/nested_cv/blca

################# Settings ###################
num_splits:  5
k_start:  0
k_end:  1
task:  survival
max_epochs:  2
results_dir:  ./results/test_results/tcga_blca__nll_surv_a0.5_lr5e-05_l2Weight_1e-05_5foldcv_b1_survival_months_dim1_256_patches_4096_wsiDim_256_epochs_2_fusion_None_modality_snn_pathT_combine
lr:  5e-05
experiment:  tcga_blca
reg:  1e-05
bag_loss:  nll_surv
seed:  42
weighted_sample:  True
opt:  adam
num_patches:  4096
dropout:  0.25
type_of_path:  combine
split_dir:  splits/nested_cv/blca
enable_multitask:  False
multitask_weight:  0.3

Loaded clinical data from: ./datasets_csv/clinical_data/tcga_blca_clinical.csv
Clinical data shape: (423, 13)
Clinical data index (case_id) samples: ['TCGA-2F-A9KO', 'TCGA-2F-A9KP', 'TCGA-2F-A9KP', 'TCGA-2F-A9KQ', 'TCGA-2F-A9KR']
Available stages: stage
III        190
II          94
unknown     77
IV          59
I            3
Name: count, dtype: int64
label column: survival_months
number of cases 359
number of classes: 8
Using nested CV splits: splits/nested_cv/blca/nested_splits_0.csv
Defining datasets...
Using split_key='val' for validation set.
Created train and val datasets for fold 0

Training Fold 0!

Init train/val splits... 
Done!
Training on 253 samples
Validating on 50 samples

Init loss function... Done!

Init Model... ğŸš€ [Init Model] è¿è¡Œæ¨¡å¼: 3 (å¤šæ¨¡æ€èåˆ)
ğŸš€ [Model Config] è¿è¡Œæ¨¡å¼: 3 (å¤šæ¨¡æ€èåˆ)
ğŸ”¨ æ„å»ºè¶…å›¾ç»“æ„: ./datasets_csv/pathway_compositions/combine_comps.csv
ğŸ“Š è¯»å–é€šè·¯æ•°æ®æ–‡ä»¶...
   - æ•°æ®å½¢çŠ¶: (4999, 332)
   - åŸºå› æ•°é‡: 4999
   - é€šè·¯æ•°é‡: 331
ğŸ”— æ„å»ºåŸºå› -é€šè·¯å…³è”çŸ©é˜µ...
   - æ€»è¿æ¥æ•°: 9745
   - å¹³å‡æ¯ä¸ªé€šè·¯åŒ…å«åŸºå› æ•°: 29.4
   - å¹³å‡æ¯ä¸ªåŸºå› å‚ä¸é€šè·¯æ•°: 1.9
  æ„å»ºè¶…è¾¹ç»“æ„...
   - æœ‰æ•ˆè¶…è¾¹æ•°é‡: 331
   - è¶…è¾¹ç´¢å¼•å½¢çŠ¶: (2, 9745)
   - é€šè·¯å¤§å°èŒƒå›´: 1 - 199
   - é€šè·¯å¤§å°ä¸­ä½æ•°: 8.0
âœ… è¶…å›¾ç»“æ„æ„å»ºå®Œæˆ!
ğŸ’¾ ä¿å­˜è¶…å›¾ç»“æ„åˆ°ç¼“å­˜: hypergraph_cache/hypergraph_structure_30ec1ddd135fba505bc72e6c33fed21e.pkl
âœ… ç¼“å­˜ä¿å­˜æˆåŠŸ!

==============================
Model: snn
æ€»å‚æ•°é‡ (Total):      0.1115 B
å¯è®­ç»ƒå‚æ•° (Trainable): 0.1115 B
==============================


Detailed layer-by-layer parameters:
Layer:                                                    | Params: 3
Layer: pathway_encoder.hypergraph_convs.0                 | Params: 128
Layer: pathway_encoder.hypergraph_convs.0.lin             | Params: 128
Layer: pathway_encoder.hypergraph_convs.1                 | Params: 256
Layer: pathway_encoder.hypergraph_convs.1.lin             | Params: 32,768
Layer: pathway_encoder.layer_norms.0                      | Params: 256
Layer: pathway_encoder.layer_norms.1                      | Params: 512
Layer: pathway_encoder.pathway_self_attention             | Params: 197,376
Layer: pathway_encoder.pathway_self_attention.out_proj    | Params: 65,792
Layer: pathway_encoder.feature_fusion.0                   | Params: 131,328
Layer: pathway_encoder.feature_fusion.2                   | Params: 512
Layer: pathway_encoder.output_projection                  | Params: 65,792
Layer: cross_attention                                    | Params: 197,376
Layer: cross_attention.out_proj                           | Params: 65,792
Layer: query_projection                                   | Params: 131,328
Layer: clinical_bert_model.embeddings.word_embeddings     | Params: 22,268,928
Layer: clinical_bert_model.embeddings.position_embeddings | Params: 393,216
Layer: clinical_bert_model.embeddings.token_type_embeddings | Params: 1,536
Layer: clinical_bert_model.embeddings.LayerNorm           | Params: 1,536
Layer: clinical_bert_model.encoder.layer.0.attention.self.query | Params: 590,592
Layer: clinical_bert_model.encoder.layer.0.attention.self.key | Params: 590,592
Layer: clinical_bert_model.encoder.layer.0.attention.self.value | Params: 590,592
Layer: clinical_bert_model.encoder.layer.0.attention.output.dense | Params: 590,592
Layer: clinical_bert_model.encoder.layer.0.attention.output.LayerNorm | Params: 1,536
Layer: clinical_bert_model.encoder.layer.0.intermediate.dense | Params: 2,362,368
Layer: clinical_bert_model.encoder.layer.0.output.dense   | Params: 2,360,064
Layer: clinical_bert_model.encoder.layer.0.output.LayerNorm | Params: 1,536
Layer: clinical_bert_model.encoder.layer.1.attention.self.query | Params: 590,592
Layer: clinical_bert_model.encoder.layer.1.attention.self.key | Params: 590,592
Layer: clinical_bert_model.encoder.layer.1.attention.self.value | Params: 590,592
Layer: clinical_bert_model.encoder.layer.1.attention.output.dense | Params: 590,592
Layer: clinical_bert_model.encoder.layer.1.attention.output.LayerNorm | Params: 1,536
Layer: clinical_bert_model.encoder.layer.1.intermediate.dense | Params: 2,362,368
Layer: clinical_bert_model.encoder.layer.1.output.dense   | Params: 2,360,064
Layer: clinical_bert_model.encoder.layer.1.output.LayerNorm | Params: 1,536
Layer: clinical_bert_model.encoder.layer.2.attention.self.query | Params: 590,592
Layer: clinical_bert_model.encoder.layer.2.attention.self.key | Params: 590,592
Layer: clinical_bert_model.encoder.layer.2.attention.self.value | Params: 590,592
Layer: clinical_bert_model.encoder.layer.2.attention.output.dense | Params: 590,592
Layer: clinical_bert_model.encoder.layer.2.attention.output.LayerNorm | Params: 1,536
Layer: clinical_bert_model.encoder.layer.2.intermediate.dense | Params: 2,362,368
Layer: clinical_bert_model.encoder.layer.2.output.dense   | Params: 2,360,064
Layer: clinical_bert_model.encoder.layer.2.output.LayerNorm | Params: 1,536
Layer: clinical_bert_model.encoder.layer.3.attention.self.query | Params: 590,592
Layer: clinical_bert_model.encoder.layer.3.attention.self.key | Params: 590,592
Layer: clinical_bert_model.encoder.layer.3.attention.self.value | Params: 590,592
Layer: clinical_bert_model.encoder.layer.3.attention.output.dense | Params: 590,592
Layer: clinical_bert_model.encoder.layer.3.attention.output.LayerNorm | Params: 1,536
Layer: clinical_bert_model.encoder.layer.3.intermediate.dense | Params: 2,362,368
Layer: clinical_bert_model.encoder.layer.3.output.dense   | Params: 2,360,064
Layer: clinical_bert_model.encoder.layer.3.output.LayerNorm | Params: 1,536
Layer: clinical_bert_model.encoder.layer.4.attention.self.query | Params: 590,592
Layer: clinical_bert_model.encoder.layer.4.attention.self.key | Params: 590,592
Layer: clinical_bert_model.encoder.layer.4.attention.self.value | Params: 590,592
Layer: clinical_bert_model.encoder.layer.4.attention.output.dense | Params: 590,592
Layer: clinical_bert_model.encoder.layer.4.attention.output.LayerNorm | Params: 1,536
Layer: clinical_bert_model.encoder.layer.4.intermediate.dense | Params: 2,362,368
Layer: clinical_bert_model.encoder.layer.4.output.dense   | Params: 2,360,064
Layer: clinical_bert_model.encoder.layer.4.output.LayerNorm | Params: 1,536
Layer: clinical_bert_model.encoder.layer.5.attention.self.query | Params: 590,592
Layer: clinical_bert_model.encoder.layer.5.attention.self.key | Params: 590,592
Layer: clinical_bert_model.encoder.layer.5.attention.self.value | Params: 590,592
Layer: clinical_bert_model.encoder.layer.5.attention.output.dense | Params: 590,592
Layer: clinical_bert_model.encoder.layer.5.attention.output.LayerNorm | Params: 1,536
Layer: clinical_bert_model.encoder.layer.5.intermediate.dense | Params: 2,362,368
Layer: clinical_bert_model.encoder.layer.5.output.dense   | Params: 2,360,064
Layer: clinical_bert_model.encoder.layer.5.output.LayerNorm | Params: 1,536
Layer: clinical_bert_model.encoder.layer.6.attention.self.query | Params: 590,592
Layer: clinical_bert_model.encoder.layer.6.attention.self.key | Params: 590,592
Layer: clinical_bert_model.encoder.layer.6.attention.self.value | Params: 590,592
Layer: clinical_bert_model.encoder.layer.6.attention.output.dense | Params: 590,592
Layer: clinical_bert_model.encoder.layer.6.attention.output.LayerNorm | Params: 1,536
Layer: clinical_bert_model.encoder.layer.6.intermediate.dense | Params: 2,362,368
Layer: clinical_bert_model.encoder.layer.6.output.dense   | Params: 2,360,064
Layer: clinical_bert_model.encoder.layer.6.output.LayerNorm | Params: 1,536
Layer: clinical_bert_model.encoder.layer.7.attention.self.query | Params: 590,592
Layer: clinical_bert_model.encoder.layer.7.attention.self.key | Params: 590,592
Layer: clinical_bert_model.encoder.layer.7.attention.self.value | Params: 590,592
Layer: clinical_bert_model.encoder.layer.7.attention.output.dense | Params: 590,592
Layer: clinical_bert_model.encoder.layer.7.attention.output.LayerNorm | Params: 1,536
Layer: clinical_bert_model.encoder.layer.7.intermediate.dense | Params: 2,362,368
Layer: clinical_bert_model.encoder.layer.7.output.dense   | Params: 2,360,064
Layer: clinical_bert_model.encoder.layer.7.output.LayerNorm | Params: 1,536
Layer: clinical_bert_model.encoder.layer.8.attention.self.query | Params: 590,592
Layer: clinical_bert_model.encoder.layer.8.attention.self.key | Params: 590,592
Layer: clinical_bert_model.encoder.layer.8.attention.self.value | Params: 590,592
Layer: clinical_bert_model.encoder.layer.8.attention.output.dense | Params: 590,592
Layer: clinical_bert_model.encoder.layer.8.attention.output.LayerNorm | Params: 1,536
Layer: clinical_bert_model.encoder.layer.8.intermediate.dense | Params: 2,362,368
Layer: clinical_bert_model.encoder.layer.8.output.dense   | Params: 2,360,064
Layer: clinical_bert_model.encoder.layer.8.output.LayerNorm | Params: 1,536
Layer: clinical_bert_model.encoder.layer.9.attention.self.query | Params: 590,592
Layer: clinical_bert_model.encoder.layer.9.attention.self.key | Params: 590,592
Layer: clinical_bert_model.encoder.layer.9.attention.self.value | Params: 590,592
Layer: clinical_bert_model.encoder.layer.9.attention.output.dense | Params: 590,592
Layer: clinical_bert_model.encoder.layer.9.attention.output.LayerNorm | Params: 1,536
Layer: clinical_bert_model.encoder.layer.9.intermediate.dense | Params: 2,362,368
Layer: clinical_bert_model.encoder.layer.9.output.dense   | Params: 2,360,064
Layer: clinical_bert_model.encoder.layer.9.output.LayerNorm | Params: 1,536
Layer: clinical_bert_model.encoder.layer.10.attention.self.query | Params: 590,592
Layer: clinical_bert_model.encoder.layer.10.attention.self.key | Params: 590,592
Layer: clinical_bert_model.encoder.layer.10.attention.self.value | Params: 590,592
Layer: clinical_bert_model.encoder.layer.10.attention.output.dense | Params: 590,592
Layer: clinical_bert_model.encoder.layer.10.attention.output.LayerNorm | Params: 1,536
Layer: clinical_bert_model.encoder.layer.10.intermediate.dense | Params: 2,362,368
Layer: clinical_bert_model.encoder.layer.10.output.dense  | Params: 2,360,064
Layer: clinical_bert_model.encoder.layer.10.output.LayerNorm | Params: 1,536
Layer: clinical_bert_model.encoder.layer.11.attention.self.query | Params: 590,592
Layer: clinical_bert_model.encoder.layer.11.attention.self.key | Params: 590,592
Layer: clinical_bert_model.encoder.layer.11.attention.self.value | Params: 590,592
Layer: clinical_bert_model.encoder.layer.11.attention.output.dense | Params: 590,592
Layer: clinical_bert_model.encoder.layer.11.attention.output.LayerNorm | Params: 1,536
Layer: clinical_bert_model.encoder.layer.11.intermediate.dense | Params: 2,362,368
Layer: clinical_bert_model.encoder.layer.11.output.dense  | Params: 2,360,064
Layer: clinical_bert_model.encoder.layer.11.output.LayerNorm | Params: 1,536
Layer: clinical_bert_model.pooler.dense                   | Params: 590,592
Layer: fc_omic.0.0                                        | Params: 1,280,000
Layer: fc_omic.1.0                                        | Params: 65,792
Layer: survival_classifier                                | Params: 5,124
Layer: text_classifier                                    | Params: 1,028
Layer: gene_classifier                                    | Params: 1,028
Layer: lin_weight                                         | Params: 769
Layer: text_projection                                    | Params: 196,864
Layer: gated_fusion_survival                              | Params: 3
Layer: gated_fusion_survival.gate_network.0               | Params: 196,864
Layer: gated_fusion_survival.gate_network.3               | Params: 771
Layer: gated_fusion_survival.fusion_projection.0          | Params: 196,864
Layer: gated_fusion_survival.fusion_projection.3          | Params: 65,792
Layer: gated_fusion_stage                                 | Params: 2
Layer: gated_fusion_stage.gate_network.0                  | Params: 131,328
Layer: gated_fusion_stage.gate_network.3                  | Params: 514
Layer: gated_fusion_stage.fusion_projection.0             | Params: 131,328
Layer: gated_fusion_stage.fusion_projection.3             | Params: 65,792
Done!
Total number of parameters: 111539482
Total number of trainable parameters: 111539482

Init optimizer ... [Config] Using unified lr for text_lr: 5e-05
[Config] Using unified lr for gene_lr: 5e-05
[Learning Rate Config] Unified LR: 5e-05 (Text LR: 5e-05, Gene LR: 5e-05)
[Learning Rate Config] Strategy: Unified

Init Loaders... Done!
[Debug] å¤šæ¨¡æ€æ¨¡å¼: cat_embeddings shape = torch.Size([1, 1280])
Traceback (most recent call last):
  File "main.py", line 325, in <module>
    results = main(args)
  File "main.py", line 60, in main
    fold_results = _train_val_with_km_plots(datasets, i, args)
  File "/root/autodl-tmp/newcfdemo/CFdemo_gene_text_copy/utils/core_utils.py", line 1507, in _train_val_with_km_plots
    test_results, train_results, metrics = _step_with_train_test_results(
  File "/root/autodl-tmp/newcfdemo/CFdemo_gene_text_copy/utils/core_utils.py", line 1352, in _step_with_train_test_results
    _train_loop_survival(epoch, model, args.modality, train_loader, optimizer, scheduler, loss_fn, args.enable_multitask)
  File "/root/autodl-tmp/newcfdemo/CFdemo_gene_text_copy/utils/core_utils.py", line 829, in _train_loop_survival
    survival_logits, logits_text, logit_te, logit_tie, logits_nde, _ = output
ValueError: not enough values to unpack (expected 6, got 2)
