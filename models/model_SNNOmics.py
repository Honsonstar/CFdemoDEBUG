from collections import OrderedDict
from os.path import join
import pdb
from transformers import AutoTokenizer, AutoModel
import numpy as np
import string

import torch
import torch.nn as nn
import torch.nn.functional as F

from models.model_utils import *
from torch_geometric.nn import GCNConv, GATConv, GraphSAGE, global_mean_pool, global_max_pool
from torch_geometric.utils import to_networkx, from_networkx
from torch_geometric.data import Data, Batch
import pickle
import os

import torch
import torch.nn as nn
import torch.nn.functional as F
import pandas as pd
import numpy as np
from torch_geometric.nn import HypergraphConv
from torch_geometric.data import Data
import pickle
import hashlib
from pathlib import Path
import matplotlib.pyplot as plt
import seaborn as sns

class HypergraphPathwayEncoder(nn.Module):
    """
    å®Œæ•´çš„è¶…å›¾é€šè·¯ç¼–ç å™¨
    """
    def __init__(self, 
                 pathway_file_path,
                 cache_dir="./hypergraph_cache",
                 input_dim=1, 
                 hidden_dim=128, 
                 output_dim=256, 
                 num_layers=1):
        super().__init__()
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(exist_ok=True)
        # åŠ è½½å¹¶æ„å»ºå›ºå®šçš„è¶…å›¾ç»“æ„
        self.hypergraph_structure = self._load_or_build_hypergraph_structure(pathway_file_path)
        self.num_genes = self.hypergraph_structure['num_genes']  # 4999
        self.num_pathways = self.hypergraph_structure['num_pathways']  # 331
        
        # æ³¨å†Œä¸ºbufferï¼Œä¸å‚ä¸æ¢¯åº¦è®¡ç®—ä½†ä¼šä¿å­˜åˆ°æ¨¡å‹çŠ¶æ€
        self.register_buffer('incident_matrix', 
                           torch.tensor(self.hypergraph_structure['incident_matrix'], 
                                      dtype=torch.float32))
        
        # è¶…å›¾å·ç§¯å±‚
        self.hypergraph_convs = nn.ModuleList([
            HypergraphConv(input_dim if i == 0 else hidden_dim, 
                          hidden_dim if i < num_layers-1 else output_dim)
            for i in range(num_layers)
        ])
        
        # å±‚å½’ä¸€åŒ–
        self.layer_norms = nn.ModuleList([
            nn.LayerNorm(hidden_dim if i < num_layers-1 else output_dim)
            for i in range(num_layers)
        ])
        
        self.pathway_self_attention = nn.MultiheadAttention(
            embed_dim=output_dim, 
            num_heads=1, 
            batch_first=True
        )
        
        # ç‰¹å¾èåˆå±‚
        self.feature_fusion = nn.Sequential(
            nn.Linear(output_dim * 2, output_dim),
            nn.ReLU(),
            nn.LayerNorm(output_dim),
            nn.Dropout(0.1)
        )
        
        # è¾“å‡ºæŠ•å½±å±‚
        self.output_projection = nn.Linear(output_dim, output_dim)

    def _get_cache_filename(self, pathway_file_path):
        """
        æ ¹æ®åŸå§‹æ–‡ä»¶è·¯å¾„å’Œå†…å®¹ç”Ÿæˆç¼“å­˜æ–‡ä»¶å
        """
        # è·å–æ–‡ä»¶çš„ä¿®æ”¹æ—¶é—´å’Œå¤§å°ä½œä¸ºå”¯ä¸€æ ‡è¯†
        file_stat = os.stat(pathway_file_path)
        file_info = f"{pathway_file_path}_{file_stat.st_mtime}_{file_stat.st_size}"
        
        # ç”ŸæˆMD5å“ˆå¸Œä½œä¸ºç¼“å­˜æ–‡ä»¶å
        hash_object = hashlib.md5(file_info.encode())
        cache_filename = f"hypergraph_structure_{hash_object.hexdigest()}.pkl"
        
        return self.cache_dir / cache_filename
    
    def _load_or_build_hypergraph_structure(self, pathway_file_path, force_rebuild=False):
        """
        åŠ è½½æˆ–æ„å»ºè¶…å›¾ç»“æ„ï¼ˆå¸¦ç¼“å­˜æœºåˆ¶ï¼‰
        """
        cache_file = self._get_cache_filename(pathway_file_path)
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦é‡æ–°æ„å»º
        if not force_rebuild and cache_file.exists():
            try:
                print(f"ğŸ”„ ä»ç¼“å­˜åŠ è½½è¶…å›¾ç»“æ„: {cache_file}")
                with open(cache_file, 'rb') as f:
                    hypergraph_structure = pickle.load(f)
                
                # éªŒè¯ç¼“å­˜æ•°æ®å®Œæ•´æ€§
                required_keys = ['genes', 'pathways', 'num_genes', 'num_pathways', 
                               'incident_matrix', 'hyperedges', 'hyperedge_index']
                if all(key in hypergraph_structure for key in required_keys):
                    print(f"âœ… ç¼“å­˜åŠ è½½æˆåŠŸ!")
                    return hypergraph_structure
                else:
                    print("âš ï¸  ç¼“å­˜æ–‡ä»¶æŸåï¼Œé‡æ–°æ„å»º...")
            except Exception as e:
                print(f"âš ï¸  ç¼“å­˜åŠ è½½å¤±è´¥: {e}ï¼Œé‡æ–°æ„å»º...")
        
        # é‡æ–°æ„å»ºè¶…å›¾ç»“æ„
        print(f"ğŸ”¨ æ„å»ºè¶…å›¾ç»“æ„: {pathway_file_path}")
        hypergraph_structure = self._build_hypergraph_structure_from_file(pathway_file_path)
        
        # ä¿å­˜åˆ°ç¼“å­˜
        try:
            print(f"ğŸ’¾ ä¿å­˜è¶…å›¾ç»“æ„åˆ°ç¼“å­˜: {cache_file}")
            with open(cache_file, 'wb') as f:
                pickle.dump(hypergraph_structure, f)
            print(f"âœ… ç¼“å­˜ä¿å­˜æˆåŠŸ!")
        except Exception as e:
            print(f"âš ï¸  ç¼“å­˜ä¿å­˜å¤±è´¥: {e}")
        
        return hypergraph_structure
    
    def _build_hypergraph_structure_from_file(self, pathway_file_path):
        """
        ä»CSVæ–‡ä»¶æ„å»ºè¶…å›¾ç»“æ„ï¼ˆå®é™…å¤„ç†é€»è¾‘ï¼‰
        """
        print("ğŸ“Š è¯»å–é€šè·¯æ•°æ®æ–‡ä»¶...")
        
        # è¯»å–æ•°æ®
        df = pd.read_csv(pathway_file_path)
        print(f"   - æ•°æ®å½¢çŠ¶: {df.shape}")
        
        # åŸºå› åˆ—è¡¨
        genes = df['gene'].tolist()
        print(f"   - åŸºå› æ•°é‡: {len(genes)}")
        
        # é€šè·¯åˆ—è¡¨ (æ’é™¤geneåˆ—)
        pathways = df.columns[1:].tolist()
        print(f"   - é€šè·¯æ•°é‡: {len(pathways)}")
        
        # åŸºå› -é€šè·¯å…³è”çŸ©é˜µ (4999 x 331)
        print("ğŸ”— æ„å»ºåŸºå› -é€šè·¯å…³è”çŸ©é˜µ...")
        incident_matrix = df.iloc[:, 1:].values.astype(np.float32)
        
        # ç»Ÿè®¡ä¿¡æ¯
        total_connections = int(incident_matrix.sum())
        avg_genes_per_pathway = incident_matrix.sum(axis=0).mean()
        avg_pathways_per_gene = incident_matrix.sum(axis=1).mean()
        
        print(f"   - æ€»è¿æ¥æ•°: {total_connections}")
        print(f"   - å¹³å‡æ¯ä¸ªé€šè·¯åŒ…å«åŸºå› æ•°: {avg_genes_per_pathway:.1f}")
        print(f"   - å¹³å‡æ¯ä¸ªåŸºå› å‚ä¸é€šè·¯æ•°: {avg_pathways_per_gene:.1f}")
        
        # æ„å»ºè¶…è¾¹åˆ—è¡¨å’Œç´¢å¼•
        print("  æ„å»ºè¶…è¾¹ç»“æ„...")
        hyperedges = []
        hyperedge_index = []
        
        for pathway_idx, pathway in enumerate(pathways):
            # æ‰¾åˆ°å±äºè¯¥é€šè·¯çš„åŸºå› 
            gene_indices = np.where(incident_matrix[:, pathway_idx] == 1)[0]
            
            if len(gene_indices) > 0:
                hyperedges.append({
                    'pathway_idx': pathway_idx,
                    'pathway_name': pathway,
                    'gene_indices': gene_indices.tolist(),
                    'size': len(gene_indices)
                })
                
                # æ„å»ºè¶…è¾¹ç´¢å¼• (ç”¨äºPyTorch Geometric)
                for gene_idx in gene_indices:
                    hyperedge_index.append([gene_idx, pathway_idx])
        
        hyperedge_index = np.array(hyperedge_index).T  # [2, num_connections]
        
        print(f"   - æœ‰æ•ˆè¶…è¾¹æ•°é‡: {len(hyperedges)}")
        print(f"   - è¶…è¾¹ç´¢å¼•å½¢çŠ¶: {hyperedge_index.shape}")
        
        # åˆ†æé€šè·¯å¤§å°åˆ†å¸ƒ
        pathway_sizes = [he['size'] for he in hyperedges]
        print(f"   - é€šè·¯å¤§å°èŒƒå›´: {min(pathway_sizes)} - {max(pathway_sizes)}")
        print(f"   - é€šè·¯å¤§å°ä¸­ä½æ•°: {np.median(pathway_sizes)}")
        
        structure = {
            'genes': genes,
            'pathways': pathways,
            'num_genes': len(genes),
            'num_pathways': len(pathways),
            'incident_matrix': incident_matrix,
            'hyperedges': hyperedges,
            'hyperedge_index': hyperedge_index,
            # æ·»åŠ å…ƒæ•°æ®
            'metadata': {
                'total_connections': total_connections,
                'avg_genes_per_pathway': float(avg_genes_per_pathway),
                'avg_pathways_per_gene': float(avg_pathways_per_gene),
                'pathway_size_range': (int(min(pathway_sizes)), int(max(pathway_sizes))),
                'pathway_size_median': float(np.median(pathway_sizes))
            }
        }
        
        print("âœ… è¶…å›¾ç»“æ„æ„å»ºå®Œæˆ!")
        return structure
    
    def forward(self, patient_expression_batch):
        """
        å®Œæ•´çš„å‰å‘ä¼ æ’­
        
        Args:
            patient_expression_batch: [batch_size, num_genes] æ‚£è€…åŸºå› è¡¨è¾¾æ•°æ®
            
        Returns:
            pathway_tokens: [batch_size, num_pathways, output_dim] é€šè·¯tokens
        """
        batch_size = patient_expression_batch.size(0)
        device = patient_expression_batch.device
        
        # ç¡®ä¿è¾“å…¥ç»´åº¦æ­£ç¡®
        assert patient_expression_batch.size(1) == self.num_genes, \
            f"Expected {self.num_genes} genes, got {patient_expression_batch.size(1)}"
        
        # å­˜å‚¨æ‰€æœ‰æ‚£è€…çš„pathway tokens
        all_pathway_tokens = []
        
        for batch_idx in range(batch_size):
            patient_expression = patient_expression_batch[batch_idx]  # [num_genes]
            
            # === æ–¹æ³•1: è¶…å›¾ç¥ç»ç½‘ç»œç¼–ç  ===
            hypergraph_tokens_x = self._encode_with_hypergraph(patient_expression, device)
            all_pathway_tokens.append(hypergraph_tokens_x)
        
        # åˆå¹¶æ‰¹æ¬¡
        pathway_tokens = torch.stack(all_pathway_tokens, dim=0).squeeze(2)
        # print('pathway_tokens.shape', pathway_tokens.shape) # torch.Size([1, 4999])
        return pathway_tokens
    
    def _encode_with_hypergraph(self, patient_expression, device):
        """
        ä½¿ç”¨è¶…å›¾ç¥ç»ç½‘ç»œç¼–ç 
        """
        # æ„å»ºèŠ‚ç‚¹ç‰¹å¾ [num_genes, 1]
        node_features = patient_expression.unsqueeze(1).float()
        
        # è·å–è¶…è¾¹ç´¢å¼•
        hyperedge_index = torch.tensor(
            self.hypergraph_structure['hyperedge_index'], 
            dtype=torch.long, 
            device=device
        )
        
        # å¤šå±‚è¶…å›¾å·ç§¯
        x = node_features
        for i, (conv, norm) in enumerate(zip(self.hypergraph_convs, self.layer_norms)):
            x = conv(x, hyperedge_index)
            x = norm(x)
            if i < len(self.hypergraph_convs) - 1:
                x = F.relu(x)
                x = F.dropout(x, p=0.1, training=self.training)
        
        # å°†åŸºå› çº§åˆ«ç‰¹å¾èšåˆåˆ°é€šè·¯çº§åˆ«
        # print('x åœ¨è¶…å›¾åçš„ shape:', x.shape)
        # exit(0)
        pathway_embeddings = self._aggregate_genes_to_pathways(x, device)
        # é€šè·¯é—´è‡ªæ³¨æ„åŠ›
        pathway_embeddings = pathway_embeddings.unsqueeze(0)  # [1, num_pathways, dim]
        attended_pathways, _ = self.pathway_self_attention(
            pathway_embeddings, pathway_embeddings, pathway_embeddings
        )
        
        return attended_pathways.squeeze(0)  # [num_pathways, dim]
    
    def _aggregate_genes_to_pathways(self, gene_embeddings, device):
        """
        å°†åŸºå› çº§åˆ«åµŒå…¥èšåˆåˆ°é€šè·¯çº§åˆ«
        """
        pathway_embeddings = torch.zeros(
            self.num_pathways, 
            gene_embeddings.size(1), 
            device=device
        )
        
        incident_matrix = self.incident_matrix.to(device)
        
        for pathway_idx in range(self.num_pathways):
            # è·å–è¯¥é€šè·¯çš„åŸºå› mask
            gene_mask = incident_matrix[:, pathway_idx] == 1
            
            if gene_mask.sum() > 0:
                # å¯¹è¯¥é€šè·¯çš„åŸºå› åµŒå…¥æ±‚å¹³å‡
                pathway_embeddings[pathway_idx] = gene_embeddings[gene_mask].mean(dim=0)
        
        return pathway_embeddings
    
    def _encode_with_sparse_mlp(self, patient_expression, device):
        """
        ä½¿ç”¨ç¨€ç–MLPç¼–ç  (åŸSURVPATHæ–¹æ³•)
        """
        sparse_pathway_tokens = []
        incident_matrix = self.incident_matrix.to(device)
        
        for pathway_idx in range(self.num_pathways):
            mlp = self.sparse_mlps[pathway_idx]
            
            if mlp is not None:
                # è·å–è¯¥é€šè·¯çš„åŸºå› è¡¨è¾¾
                gene_mask = incident_matrix[:, pathway_idx] == 1
                pathway_genes = patient_expression[gene_mask]
                
                # é€šè¿‡MLPç¼–ç 
                pathway_token = mlp(pathway_genes)
                sparse_pathway_tokens.append(pathway_token)
            else:
                # ç©ºé€šè·¯ç”¨é›¶å‘é‡
                sparse_pathway_tokens.append(
                    torch.zeros(self.hypergraph_convs[-1].out_channels, device=device)
                )
        
        return torch.stack(sparse_pathway_tokens)  # [num_pathways, dim]
    
    def _fuse_features(self, hypergraph_tokens, sparse_tokens):
        """
        èåˆè¶…å›¾ç‰¹å¾å’Œç¨€ç–MLPç‰¹å¾
        """
        # æ‹¼æ¥ä¸¤ç§ç‰¹å¾
        concatenated = torch.cat([hypergraph_tokens, sparse_tokens], dim=-1)
        
        # é€šè¿‡èåˆå±‚
        fused = self.feature_fusion(concatenated)
        
        return fused

class GatedFusion(nn.Module):
    """
    é—¨æ§èåˆæ¨¡å— - è®©ç½‘ç»œè‡ªåŠ¨å­¦ä¹ å¤šæ¨¡æ€èåˆæƒé‡
    ã€å·²æ”¹ã€‘å®ç°è‡ªé€‚åº”æƒé‡å­¦ä¹ ï¼Œæ›¿ä»£ç®€å•ç›¸åŠ 
    """
    def __init__(self, feature_dim: int, num_modalities: int = 3):
        """
        Args:
            feature_dim: æ¯ä¸ªæ¨¡æ€çš„ç‰¹å¾ç»´åº¦
            num_modalities: æ¨¡æ€æ•°é‡ (é»˜è®¤3: åŸºå› /é€šè·¯/æ–‡æœ¬)
        """
        super(GatedFusion, self).__init__()
        self.feature_dim = feature_dim
        self.num_modalities = num_modalities

        # ã€å·²æ”¹ã€‘ä¸ºæ¯ä¸ªæ¨¡æ€åˆ›å»ºå¯å­¦ä¹ çš„é—¨æ§æƒé‡
        self.gate_weights = nn.Parameter(torch.ones(num_modalities) / num_modalities)

        # ã€å·²æ”¹ã€‘åˆ›å»ºé—¨æ§ç½‘ç»œï¼ŒåŸºäºè¾“å…¥ç‰¹å¾åŠ¨æ€è°ƒæ•´æƒé‡
        self.gate_network = nn.Sequential(
            nn.Linear(feature_dim * num_modalities, feature_dim),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(feature_dim, num_modalities),
            nn.Softmax(dim=1)  # ç¡®ä¿æƒé‡å’Œä¸º1
        )

        # ã€å·²æ”¹ã€‘èåˆåçš„ç‰¹å¾æŠ•å½±
        self.fusion_projection = nn.Sequential(
            nn.Linear(feature_dim * num_modalities, feature_dim),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(feature_dim, feature_dim)
        )

    def forward(self, modality_features):
        """
        Args:
            modality_features: List of tensors, each [batch_size, feature_dim]
                             é•¿åº¦åº”è¯¥ç­‰äºnum_modalities

        Returns:
            fused_features: [batch_size, feature_dim]
            gate_weights: [batch_size, num_modalities] - å­¦ä¹ åˆ°çš„æƒé‡
        """
        batch_size = modality_features[0].size(0)
        device = modality_features[0].device

        # ç¡®ä¿è¾“å…¥æ•°é‡æ­£ç¡®
        assert len(modality_features) == self.num_modalities, \
            f"Expected {self.num_modalities} modalities, got {len(modality_features)}"

        # ã€å·²æ”¹ã€‘æ–¹æ³•1: ä½¿ç”¨å¯å­¦ä¹ çš„é™æ€æƒé‡
        static_weights = F.softmax(self.gate_weights, dim=0)

        # ã€å·²æ”¹ã€‘æ–¹æ³•2: ä½¿ç”¨åŠ¨æ€é—¨æ§ç½‘ç»œ
        concatenated = torch.cat(modality_features, dim=1)  # [batch_size, feature_dim * num_modalities]
        dynamic_weights = self.gate_network(concatenated)  # [batch_size, num_modalities]

        # ã€å·²æ”¹ã€‘ç»“åˆé™æ€å’ŒåŠ¨æ€æƒé‡ (80%åŠ¨æ€ + 20%é™æ€)
        final_weights = 0.8 * dynamic_weights + 0.2 * static_weights.unsqueeze(0).expand(batch_size, -1)

        # ã€å·²æ”¹ã€‘åº”ç”¨é—¨æ§æƒé‡è¿›è¡ŒåŠ æƒèåˆ
        weighted_features = []
        for i, features in enumerate(modality_features):
            weighted_features.append(features * final_weights[:, i:i+1])

        # ã€å·²æ”¹ã€‘èåˆæ‰€æœ‰åŠ æƒç‰¹å¾
        fused = torch.cat(weighted_features, dim=1)  # [batch_size, feature_dim * num_modalities]

        # ã€å·²æ”¹ã€‘é€šè¿‡æŠ•å½±å±‚å¾—åˆ°æœ€ç»ˆèåˆç‰¹å¾
        output = self.fusion_projection(fused)  # [batch_size, feature_dim]

        return output, final_weights

class SNNOmics(nn.Module):
    def __init__(self, omic_input_dim: int, model_size_omic: str='small', n_classes: int=4,
                 n_stage_classes: int=4, enable_multitask: bool=False, multitask_weight: float=0.3,
                 graph_data_path: str="graph_data.pkl", ab_model: int=3):
        """
        SNNOmicså¤šæ¨¡æ€ç”Ÿå­˜é¢„æµ‹æ¨¡å‹

        Args:
            omic_input_dim: åŸºå› /ç»„å­¦æ•°æ®ç»´åº¦
            model_size_omic: åŸºå› ç½‘ç»œå¤§å° ('small' æˆ– 'big')
            n_classes: ç”Ÿå­˜é¢„æµ‹ç±»åˆ«æ•°
            n_stage_classes: åˆ†æœŸé¢„æµ‹ç±»åˆ«æ•°
            enable_multitask: æ˜¯å¦å¯ç”¨å¤šä»»åŠ¡å­¦ä¹ ï¼ˆç”Ÿå­˜+åˆ†æœŸï¼‰
            multitask_weight: å¤šä»»åŠ¡æƒé‡
            graph_data_path: å›¾æ•°æ®è·¯å¾„
            ab_model: ã€æ–°å¢ã€‘è¿è¡Œæ¨¡å¼æ§åˆ¶
                      1 = ä»…æ–‡æœ¬æ¨¡å¼ (only_text)
                      2 = ä»…åŸºå› æ¨¡å¼ (only_omic)
                      3 = å¤šæ¨¡æ€èåˆæ¨¡å¼ (åŸºå› +æ–‡æœ¬)ã€é»˜è®¤ã€‘
        """
        super(SNNOmics, self).__init__()

        # ã€æ–°å¢ã€‘å­˜å‚¨è¿è¡Œæ¨¡å¼
        self.ab_model = ab_model
        print(f"ğŸš€ [Model Config] è¿è¡Œæ¨¡å¼: {ab_model} "
              f"({'ä»…æ–‡æœ¬' if ab_model == 1 else 'ä»…åŸºå› ' if ab_model == 2 else 'å¤šæ¨¡æ€èåˆ'})")

        self.size_dict_omic = {'small': [256, 256], 'big': [1024, 1024, 1024, 256]}
        # self.size_dict_omic = {'small': [512, 512], 'big': [1024, 1024, 1024, 256]}
        # self.size_dict_omic = {'small': [768, 768], 'big': [1024, 1024, 1024, 256]}
        ### Constructing Genomic SNN
        hidden = self.size_dict_omic[model_size_omic]
        self.target_dim = hidden[-1]

        # é€šè·¯ç¼–ç å™¨
        # === [ä¿®æ”¹] åˆ¤æ–­æ˜¯å¦ä½¿ç”¨é€šè·¯ç¼–ç å™¨ ===
        # åŸæœ‰çš„ combine æ•°æ®ç»´åº¦é€šå¸¸æ˜¯ 4999ã€‚å¦‚æœä½ ç­›é€‰ååªæœ‰å‡ å/å‡ ç™¾ï¼Œè¯´æ˜æ˜¯è‡ªå®šä¹‰æ•°æ®ã€‚
        # æˆ‘ä»¬è®¾å®šä¸€ä¸ªé˜ˆå€¼ï¼ˆæ¯”å¦‚ 2000ï¼‰ï¼Œå°äºè¿™ä¸ªæ•°å°±ä¸åŠ è½½é€šè·¯å›¾ã€‚
        if omic_input_dim > 2000:
            self.use_pathway = True
            self.pathway_encoder = HypergraphPathwayEncoder(
                pathway_file_path='./datasets_csv/pathway_compositions/combine_comps.csv',
                output_dim=self.target_dim,
                num_layers=2
            )
            # åªæœ‰åœ¨ä½¿ç”¨é€šè·¯æ—¶æ‰åˆå§‹åŒ– Cross Attention
            self.cross_attention = nn.MultiheadAttention(
                embed_dim=self.target_dim,
                num_heads=1,
                batch_first=True
            )
            self.query_projection = nn.Linear(self.target_dim + hidden[-1], self.target_dim)
        else:
            print(f"ğŸ”¥ [Model Info] æ£€æµ‹åˆ°ç­›é€‰åçš„ç‰¹å¾ (Dim={omic_input_dim})ï¼Œè‡ªåŠ¨ç¦ç”¨é€šè·¯ç¼–ç å™¨ï¼Œæ”¹ç”¨ç›´æ¥æ‹¼æ¥æ¨¡å¼ã€‚")
            self.use_pathway = False
            self.pathway_encoder = None
            self.cross_attention = None
            self.query_projection = None
            # ã€æ–°å¢ã€‘ä»…åœ¨éœ€è¦æ—¶åˆå§‹åŒ–åˆ†ç±»å™¨
            if self.ab_model != 1:  # éä»…æ–‡æœ¬æ¨¡å¼éœ€è¦åˆ†ç±»å™¨
                self.survival_classifier = nn.Linear(1024, n_classes)
            #åŸä»£ç å­˜åœ¨é€»è¾‘å¤±è¯¯
            # 256*2 + 256 = 768 (å¦‚æœæ˜¯ small)
            # æˆ–è€… cat äº† text_embeddings (768) ? åŸä»£ç é‡Œ cat_embeddings = cat([gene, cross, text])
            # 256 + 256 + 768 = 1280
        # ==========================================

        
        if self.ab_model == 1: # only text
            self.use_debias = False
            self.use_align_loss = False
            self.only_omic = False
            self.only_text = True
            self.multi_model = False
            self.use_resnet = True
            self.NOT_hygraph = True
        if self.ab_model == 2: # only omic
            self.use_debias = False
            self.use_align_loss = False
            self.only_omic = True
            self.only_text = False
            self.multi_model = False
            self.use_resnet = False
            self.NOT_hygraph = True
        if self.ab_model == 3: # å¤šæ¨¡æ€ã€‚
            self.use_debias = False
            self.use_align_loss = False
            self.only_omic = False
            self.only_text = False
            self.multi_model = True
            self.use_resnet = True
            self.NOT_hygraph = True # ä¸ä½¿ç”¨è¶…å›¾
        if self.ab_model == 4: # å¤šæ¨¡æ€ã€‚æ®‹å·® + å¯¹é½æŸå¤± + å»å (å¼ºåº¦ï¼Œ) 
            self.use_debias = True
            self.use_align_loss = False
            self.only_omic = False
            self.only_text = False
            self.multi_model = True
            self.use_resnet = True
            self.NOT_hygraph = False # ä½¿ç”¨è¶…å›¾
            self.weight_debiase = 0.4 # å¦‚æœä¸º Falseï¼Œè¡¨ç¤ºç”¨å¯å­¦ä¹ çš„å‚æ•°
        if self.ab_model == 5: # å¤šæ¨¡æ€ã€‚å»åï¼ŒåŸºå› ä¸ç”¨æˆ‘ä»¬çš„æ–¹æ³•
            self.use_debias = True
            self.use_align_loss = False
            self.only_omic = False  
            self.only_text = False
            self.multi_model = True
            self.use_resnet = True
            self.NOT_hygraph = True # ä¸ä½¿ç”¨è¶…å›¾
            self.weight_debiase = 0.1 # å¦‚æœä¸º Falseï¼Œè¡¨ç¤ºç”¨å¯å­¦ä¹ çš„å‚æ•°
        
        self.clinical_bert_tokenizer = AutoTokenizer.from_pretrained("biobert")
        self.clinical_bert_model = AutoModel.from_pretrained("biobert")

        self.n_classes = n_classes      
        self.n_stage_classes = n_stage_classes
        self.enable_multitask = enable_multitask
        self.multitask_weight = multitask_weight
        
        

        fc_omic = [SNN_Block(dim1=omic_input_dim, dim2=hidden[0])]
        for i, _ in enumerate(hidden[1:]):
            fc_omic.append(SNN_Block(dim1=hidden[i], dim2=hidden[i+1], dropout=0.25))
        self.fc_omic = nn.Sequential(*fc_omic)
        
        # ã€ä¿®å¤ã€‘æ ¹æ®è¿è¡Œæ¨¡å¼åˆå§‹åŒ–survival_classifier
        if self.ab_model == 1:  # ä»…æ–‡æœ¬æ¨¡å¼
            self.survival_classifier = nn.Sequential(
                nn.Linear(768, 768 // 4),
                nn.ReLU(),
                nn.Linear(768 // 4, n_classes)
            )
        elif self.ab_model == 2:  # ä»…åŸºå› æ¨¡å¼
            self.survival_classifier = nn.Sequential(
                nn.Linear(hidden[-1], hidden[-1] // 2),
                nn.ReLU(),
                nn.Linear(hidden[-1] // 2, n_classes)
            )
        else:  # å¤šæ¨¡æ€èåˆæ¨¡å¼ (ab_model == 3)
            if self.use_pathway:
                # é€šè·¯æ¨¡å¼ï¼šGene(256) + Cross(256) + Text(768) = 1280ç»´
                self.survival_classifier = nn.Linear(1280, n_classes)
            else:
                # æ— é€šè·¯æ¨¡å¼ï¼šGene(256) + Text(768) = 1024ç»´
                self.survival_classifier = nn.Linear(1024, n_classes)
            self.only_text = False
        self.text_classifier = nn.Linear(self.target_dim, n_classes)
        self.gene_classifier = nn.Linear(hidden[-1], n_classes)
        
        # Stage prediction head (only if multitask is enabled)
        # ã€ä¿®å¤ã€‘æ ¹æ®è¿è¡Œæ¨¡å¼åˆå§‹åŒ–stage_classifier
        if self.enable_multitask:
            if self.ab_model == 1:  # ä»…æ–‡æœ¬æ¨¡å¼
                self.stage_classifier = nn.Sequential(
                    nn.Linear(768, 768 // 4),
                    nn.ReLU(),
                    nn.Linear(768 // 4, n_stage_classes)
                )
            elif self.ab_model == 2:  # ä»…åŸºå› æ¨¡å¼
                self.stage_classifier = nn.Linear(hidden[-1], n_stage_classes)
            else:  # å¤šæ¨¡æ€èåˆæ¨¡å¼ (ab_model == 3)
                self.stage_classifier = nn.Sequential(
                    nn.Linear(hidden[-1] + 768, hidden[-1]),
                    nn.ReLU(),
                    nn.Linear(hidden[-1], n_stage_classes)
                )
            self.stage_classifier_text = nn.Linear(768, n_stage_classes)

        self.constant = nn.Parameter(torch.tensor(0.0), requires_grad=True)
        self.debiase_weight = nn.Parameter(torch.tensor(0.0), requires_grad=True)
        self.lin_weight = nn.Linear(768, 1)
        
        self.debiase_weight2 = nn.Parameter(torch.tensor(0.0), requires_grad=True)

        
        self.dropout_omic = nn.Dropout(0.3)
        init_max_weights(self)
        self.text_projection = nn.Linear(768, self.target_dim)
        self.query_projection = nn.Linear(self.target_dim + hidden[-1], self.target_dim)

        # äº¤å‰æ³¨æ„åŠ›å±‚
        self.cross_attention = nn.MultiheadAttention(
            embed_dim=self.target_dim,
            num_heads=1,
            batch_first=True  # ç¡®ä¿è¾“å…¥å½¢çŠ¶ä¸º [batch, seq, dim]
        )

        # ã€å·²æ”¹ã€‘åˆå§‹åŒ–é—¨æ§èåˆæ¨¡å—
        # å¯¹äº survival é¢„æµ‹çš„èåˆ (åŸºå›  + äº¤å‰æ³¨æ„åŠ› + æ–‡æœ¬)
        if self.use_pathway:
            self.gated_fusion_survival = GatedFusion(
                feature_dim=self.target_dim,
                num_modalities=3  # åŸºå›  + äº¤å‰æ³¨æ„åŠ› + æ–‡æœ¬
            )
        else:
            # å¦‚æœæ²¡æœ‰é€šè·¯ï¼Œä½¿ç”¨åŸºå›  + æ–‡æœ¬çš„èåˆ
            self.gated_fusion_survival = GatedFusion(
                feature_dim=self.target_dim,
                num_modalities=2  # åŸºå›  + æ–‡æœ¬
            )

        # ã€å·²æ”¹ã€‘å¯¹äº stage é¢„æµ‹çš„èåˆ (åŸºå›  + æ–‡æœ¬)
        self.gated_fusion_stage = GatedFusion(
            feature_dim=self.target_dim,
            num_modalities=2  # åŸºå›  + æ–‡æœ¬
        )
        
    def aggregate_subword_attentions(self, tokens, scores):
        """
        å°†å­è¯(subword)çš„æ³¨æ„åŠ›åˆ†æ•°åˆå¹¶åˆ°å®ƒä»¬æ‰€å±çš„å®Œæ•´å•è¯ä¸Šã€‚
        """
        word_tokens = []
        word_attentions = []
        
        current_word = ""
        current_attention = 0.0
        subword_count = 0

        # è¿‡æ»¤æ‰ç‰¹æ®Štoken [CLS], [SEP], [PAD]
        special_tokens = {self.clinical_bert_tokenizer.cls_token, 
                            self.clinical_bert_tokenizer.sep_token, 
                            self.clinical_bert_tokenizer.pad_token}

        for token, score in zip(tokens, scores):
            if token in special_tokens:
                continue

            if token.startswith("##"):
                current_word += token[2:]
                current_attention += score
                subword_count += 1
            else:
                # é‡åˆ°æ–°è¯ï¼Œå…ˆä¿å­˜ä¸Šä¸€ä¸ªè¯çš„ç»“æœ
                if current_word:
                    # ä½¿ç”¨å¹³å‡åˆ†ä½œä¸ºæ•´ä¸ªè¯çš„æ³¨æ„åŠ›
                    word_tokens.append(current_word)
                    word_attentions.append(current_attention / subword_count)
                
                # å¼€å§‹è®°å½•æ–°è¯
                current_word = token
                current_attention = score
                subword_count = 1
        
        # ä¿å­˜æœ€åä¸€ä¸ªè¯
        if current_word:
            word_tokens.append(current_word)
            word_attentions.append(current_attention / subword_count)

        return word_tokens, torch.tensor(word_attentions)


    def generate_highlighted_text(self, words, scores):
        """æ ¹æ®åˆ†æ•°ç”Ÿæˆå¸¦èƒŒæ™¯è‰²çš„é«˜äº®æ–‡æœ¬"""
        scores = scores.numpy()
        min_s, max_s = scores.min(), scores.max()
        normalized_scores = (scores - min_s) / (max_s - min_s)
        
        final_text = ""
        for word, score in zip(words, normalized_scores):
                intensity = int(255 - score * 150)
                bg_color = f"\033[48;2;255;255;{intensity}m" # é»„è‰²èƒŒæ™¯
                text_color = "\033[30m" # é»‘è‰²å­—ä½“
                reset_color = "\033[0m"
                final_text += f"{bg_color}{text_color} {word} {reset_color}"

        print("--- [Attention Visualization (Words)] ---")
        print("(é¢œè‰²è¶Šé»„ä»£è¡¨æ¨¡å‹å…³æ³¨åº¦è¶Šé«˜)")
        print(final_text.lstrip()) # lstrip()ç§»é™¤å¼€å¤´çš„ç©ºæ ¼
        print("-----------------------------------------\n")


    def visualize_keywords_in_context(self, original_words, original_scores, stop_words, punctuation, save_path=None):
        """
        åœ¨åŸæ–‡ä¸­åªé«˜äº®å…³é”®è¯ã€‚
        
        Args:
            original_words: å•è¯åˆ—è¡¨
            original_scores: attentionåˆ†æ•°åˆ—è¡¨
            stop_words: åœç”¨è¯é›†åˆ
            punctuation: æ ‡ç‚¹ç¬¦å·é›†åˆ
            save_path: ä¿å­˜HTMLæ–‡ä»¶çš„è·¯å¾„ï¼ˆæ–°å¢ï¼‰ã€‚å¦‚æœä¸ºNoneï¼Œåˆ™æ‰“å°åˆ°ç»ˆç«¯
        """
        # åˆ›å»ºä¸€ä¸ªæ–°çš„"å¯è§†åŒ–åˆ†æ•°åˆ—è¡¨"ï¼Œå°†åœç”¨è¯å’Œæ ‡ç‚¹ç¬¦å·çš„åˆ†æ•°è®¾ä¸º0
        visualization_scores = []
        for word, score in zip(original_words, original_scores):
            if word.lower() in stop_words or word in punctuation:
                visualization_scores.append(0.0)
            else:
                visualization_scores.append(score.item())
        
        # å½’ä¸€åŒ–å¯è§†åŒ–åˆ†æ•°ä»¥ä¾¿æ˜ å°„åˆ°é¢œè‰²
        scores_tensor = torch.tensor(visualization_scores)
        min_s, max_s = scores_tensor.min(), scores_tensor.max()
        
        # é˜²æ­¢æ‰€æœ‰è¯éƒ½æ˜¯åœç”¨è¯å¯¼è‡´é™¤ä»¥é›¶
        if max_s == 0:
            normalized_scores = scores_tensor
        else:
            normalized_scores = (scores_tensor - min_s) / (max_s - min_s)

        # ========== å¦‚æœæŒ‡å®šäº†save_pathï¼Œç”ŸæˆHTMLæ–‡ä»¶ ==========
        if save_path:
            html_content = """<!DOCTYPE html>
    <html>
    <head>
        <meta charset="utf-8">
        <title>æ–‡æœ¬å…³é”®è¯å¯è§†åŒ–</title>
        <style>
            body { 
                font-family: 'Arial', 'Microsoft YaHei', sans-serif;
                padding: 30px; 
                max-width: 1200px; 
                margin: 0 auto;
                background-color: #f9f9f9;
            }
            h2 {
                color: #333;
                border-bottom: 3px solid #4CAF50;
                padding-bottom: 10px;
            }
            .legend {
                margin: 20px 0;
                padding: 15px;
                background-color: #e8f5e9;
                border-left: 4px solid #4CAF50;
                border-radius: 5px;
            }
            .highlighted-text { 
                line-height: 2.2; 
                font-size: 16px;
                padding: 20px;
                background-color: white;
                border-radius: 8px;
                box-shadow: 0 2px 4px rgba(0,0,0,0.1);
            }
            .word { 
                padding: 3px 6px; 
                margin: 0 2px;
                border-radius: 4px;
                display: inline-block;
            }
        </style>
    </head>
    <body>
        <h2>ğŸ“Š æ–‡æœ¬å…³é”®è¯é‡è¦æ€§å¯è§†åŒ–</h2>
        <div class="legend">
            <strong>è¯´æ˜ï¼š</strong>é¢œè‰²è¶Šé»„ï¼ˆè¶Šäº®ï¼‰ä»£è¡¨æ¨¡å‹è¶Šå…³æ³¨è¯¥è¯ï¼Œç°è‰²è¯ä¸ºåœç”¨è¯æˆ–æ ‡ç‚¹
        </div>
        <div class="highlighted-text">
    """
            
            # ç”Ÿæˆæ¯ä¸ªè¯çš„HTML
            for word, score in zip(original_words, normalized_scores):
                score_val = score.item()
                
                if score_val == 0:
                    # åœç”¨è¯æˆ–æ ‡ç‚¹ - ç°è‰²
                    bg_color = 'rgba(200, 200, 200, 0.3)'
                else:
                    # å…³é”®è¯ - é»„è‰²æ¸å˜ï¼ˆæ ¹æ®é‡è¦æ€§ï¼‰
                    intensity = int(255 - score_val * 150)
                    bg_color = f'rgb(255, 255, {intensity})'
                
                html_content += f'<span class="word" style="background-color: {bg_color};">{word}</span>\n'
            
            html_content += """
        </div>
    </body>
    </html>
    """
            
            # ä¿å­˜HTMLæ–‡ä»¶
            with open(save_path, 'w', encoding='utf-8') as f:
                f.write(html_content)
            
        # ========== å¦åˆ™ï¼Œæ‰“å°åˆ°ç»ˆç«¯ï¼ˆä¿æŒåŸæœ‰è¡Œä¸ºï¼‰==========
        else:
            final_text = ""
            for word, score in zip(original_words, normalized_scores):
                    # score ä¸º0çš„è¯ï¼ˆåœç”¨è¯ç­‰ï¼‰intensityä¼šæœ€å¤§ï¼ŒèƒŒæ™¯è‰²æœ€æµ…
                    intensity = int(255 - score * 150)
                    bg_color = f"\033[48;2;255;255;{intensity}m" # é»„è‰²èƒŒæ™¯
                    text_color = "\033[30m" # é»‘è‰²å­—ä½“
                    reset_color = "\033[0m"
                    final_text += f"{bg_color}{text_color} {word} {reset_color}"

            print("--- [Keyword Visualization in Context] ---")
            print("(ä»…å…³é”®è¯è¢«é«˜äº®ï¼Œé¢œè‰²è¶Šé»„ä»£è¡¨æ¨¡å‹å…³æ³¨åº¦è¶Šé«˜)")
            print(final_text.lstrip())
            print("------------------------------------------\n")


    def visualize_top_pathways(self, attention_scores, pathway_names, top_k=15, save_path=None, save_figure=None):
        """
        å¯è§†åŒ–æœ€é‡è¦çš„Top-Kä¸ªé€šè·¯ã€‚

        Args:
            attention_scores (torch.Tensor): å•ä¸ªæ ·æœ¬çš„æ³¨æ„åŠ›æƒé‡ï¼Œå½¢çŠ¶ä¸º [num_pathways]ã€‚
            pathway_names (list): åŒ…å«æ‰€æœ‰é€šè·¯åç§°çš„åˆ—è¡¨ã€‚
            top_k (int): è¦æ˜¾ç¤ºçš„æœ€é‡è¦é€šè·¯çš„æ•°é‡ã€‚
            save_path (str): ä¿å­˜CSVæ–‡ä»¶çš„è·¯å¾„ï¼ˆæ–°å¢ï¼‰ã€‚å¦‚æœä¸ºNoneï¼Œåˆ™æ‰“å°åˆ°ç»ˆç«¯
            save_figure (str): ä¿å­˜å›¾ç‰‡çš„è·¯å¾„ï¼ˆæ–°å¢ï¼‰ã€‚å¦‚æœä¸ºNoneï¼Œåˆ™ä¸ä¿å­˜å›¾ç‰‡
        """
        # å°†Tensorè½¬ä¸ºnumpyæ•°ç»„
        scores = attention_scores.cpu().detach().numpy()
        
        # åˆ›å»ºDataFrameå¹¶æ’åº
        df = pd.DataFrame({
            'Pathway': pathway_names,
            'Attention_Score': scores
        })
        df_sorted = df.sort_values(by='Attention_Score', ascending=False).head(top_k)
        
        # ========== å¦‚æœæŒ‡å®šäº†save_pathï¼Œä¿å­˜CSV ==========
        if save_path:
            df_sorted.to_csv(save_path, index=False)
        # ========== ã€ä¿®æ”¹ã€‘åªæœ‰åœ¨æ—¢ä¸ä¿å­˜CSVä¹Ÿä¸ä¿å­˜å›¾ç‰‡æ—¶ï¼Œæ‰æ‰“å°åˆ°ç»ˆç«¯ ==========
        elif not save_figure:
            print(f"\n--- [æ¨¡å‹é€šè·¯è§£é‡Š] ---")
            print(f"Top {top_k} Most Important Pathways:")
            print(df_sorted)
            print("--------------------------\n")

        # ========== å¦‚æœæŒ‡å®šäº†save_figureï¼Œç”Ÿæˆå¹¶ä¿å­˜å›¾ç‰‡ ==========
        if save_figure:
            plt.figure(figsize=(10, 8))
            sns.barplot(x='Attention_Score', y='Pathway', data=df_sorted, palette='viridis')
            
            # ç¾åŒ–å›¾è¡¨
            plt.title(f'Top {top_k} Important Pathways identified by Cross-Attention', fontsize=16)
            plt.xlabel('Attention Score', fontsize=12)
            plt.ylabel('Pathway', fontsize=12)
            plt.grid(axis='x', linestyle='--', alpha=0.6)
            
            # ç¡®ä¿yè½´æ ‡ç­¾å®Œå…¨æ˜¾ç¤º
            plt.tight_layout()
            
            # ä¿å­˜å›¾ç‰‡
            plt.savefig(save_figure, dpi=300, bbox_inches='tight')
            plt.close()  # å…³é—­å›¾å½¢ï¼Œé¿å…å ç”¨å†…å­˜

    def fusion(self, z_main, z_text, z_gene, main_fact=False, text_fact=False, gene_fact=False):
        # Apply counterfactual transformations
        if not main_fact:
            z_main = self.constant * torch.ones_like(z_main).cuda()
        if not text_fact:
            z_text = self.constant * torch.ones_like(z_text).cuda()
        if not gene_fact:
            z_gene = self.constant * torch.ones_like(z_gene).cuda()
        
        # cfvqa
        # z = z_main * torch.sigmoid(z_text)
        
        z = z_main + z_text
        if z_gene is not None and gene_fact:
            z = z + z_gene
        z = torch.log(torch.sigmoid(z) + 1e-9)
        # z = torch.nn.functional.leaky_    relu(z) 
        # z = torch.log(torch.nn.functional.relu(z) + 1e-9)  # ReLU activation
        
        
        # # cat + linear fusion
        # z = torch.cat((z_main, z_text), dim=1)
        # if z_gene is not None and gene_fact:
        #     z = torch.cat((z, z_gene), dim=1)
        # z = self.fusion_lin(z)
        
        # # add + linear fusion
        # z = z_main + z_text
        # if z_gene is not None and gene_fact:
        #     z = z + z_gene
        # z = self.fusion_lin_add(z)
        
        return z
    
    def fusion_stage(self, z_main, z_text, z_gene, main_fact=False, text_fact=False, gene_fact=False):
        # Apply counterfactual transformations

        if not main_fact:
            z_main = self.constant * torch.ones_like(z_main).cuda()
        if not text_fact:
            z_text = self.constant * torch.ones_like(z_text).cuda()
        if not gene_fact:
            z_gene = self.constant * torch.ones_like(z_gene).cuda()
            
        # cfvqa
        z = z_main + z_text
        if z_gene is not None and gene_fact:
            z = z + z_gene
        # z = torch.log(torch.sigmoid(z) + 1e-9)
        z = torch.nn.functional.leaky_relu(z) 
        
        # # cat + linear fusion
        # z = torch.cat((z_main, z_text), dim=1)
        # if z_gene is not None and gene_fact:
        #     z = torch.cat((z, z_gene), dim=1)
        # z = self.fusion_lin(z)
        
        # # add + linear fusion
        # z = z_main + z_text
        # if z_gene is not None and gene_fact:
        #     z = z + z_gene
        # z = self.fusion_lin_add(z)
        
        return z
    #ä¸»è¦ä¿®æ”¹çš„åœ°æ–¹
    def forward(self, return_feats=False, **kwargs):
        # ã€åŸºå› çº§åˆ«çš„è¡¨å¾ ï¼Œ é€šè·¯çº§åˆ«çš„è¡¨å¾ï¼Œ æ–‡æœ¬çº§åˆ«çš„è¡¨å¾ã€‘
        x = kwargs['data_omics']#åŸºå› æ•°æ®
        gene_level_rep = self.fc_omic(x) # 1.åŸºå› çº§åˆ«çš„è¡¨å¾ [1, dim]ï¼Œä½¿ç”¨å…¨è¿æ¥å±‚å †å 
        # print('gene_level_rep.shape:', gene_level_rep.shape)

        #ä¿®æ”¹é€šè·¯é€»è¾‘ï¼Œåˆ°åé¢ã€‚
        #pathway_level_rep = self.pathway_encoder(x) # 2.é€šè·¯çº§åˆ«çš„è¡¨å¾  [batch_size, num_pathways, dim]
        x_text_report = kwargs['x_text_report'][-1] # æ–‡æœ¬æ•°æ®
        text_inputs = self.clinical_bert_tokenizer( # å¯¹æ–‡æœ¬è¿›è¡Œç¼–ç 
            x_text_report, 
            return_tensors="pt", 
            truncation=True, 
            padding=True, 
            max_length=512
        ).to(x.device)
        
        # outputs = self.clinical_bert_model(**text_inputs)
        outputs = self.clinical_bert_model(**text_inputs, output_attentions=True)
        # ä½¿ç”¨ [CLS] token çš„åµŒå…¥
        text_embeddings = outputs.last_hidden_state[:, 0, :] # 3.æ–‡æœ¬çº§åˆ«çš„è¡¨å¾ [batch_size, dim=768] 
        #======================================================

        #ä¿®æ”¹åé€šè·¯é€»è¾‘
        # æ³¨æ„ï¼šéœ€ç¡®ä¿ __init__ ä¸­å·²å®šä¹‰ self.use_pathway
        use_pathway = getattr(self, 'use_pathway', True) # é»˜è®¤ True ä»¥å…¼å®¹æ—§ä»£ç 

        if use_pathway:
            pathway_level_rep = self.pathway_encoder(x) 
            
            # æŠ•å½±æ–‡æœ¬ç‰¹å¾ç”¨äº Attention
            text_emb_proj = self.text_projection(text_embeddings) 
            
            combined_context = torch.cat([gene_level_rep, text_emb_proj], dim=1)
            query_rep = self.query_projection(combined_context)
            query = query_rep.unsqueeze(1)
            
            attn_output, attn_weights = self.cross_attention(
                query=query, key=pathway_level_rep, value=pathway_level_rep
            )
            cross_modal_rep = attn_output.squeeze(1)
            
            # åŸæœ‰çš„æ‹¼æ¥é€»è¾‘ (Gene + Cross + Text)
            cat_embeddings = torch.cat([gene_level_rep, cross_modal_rep, text_embeddings], dim=1)
        else:
            # === æ–°æ¨¡å¼ï¼šç›´æ¥æ‹¼æ¥ ===
            # Gene(256) + Text(768) = 1024 ç»´
            cat_embeddings = torch.cat([gene_level_rep, text_embeddings], dim=1)
            
            # è®¾ç½®ç©ºçš„ attention weights é˜²æ­¢åé¢æŠ¥é”™
            attn_weights = None




        #0117ä¿®æ”¹
        # # print('text_embeddings.shape:', text_embeddings.shape)
        # text_embeddings = self.text_projection(text_embeddings) # å˜ä¸º dim
        # # print('text_embeddings.shape:', text_embeddings.shape)

        # combined_context = torch.cat([gene_level_rep, text_embeddings], dim=1) # Shape: [B, 512]
        # query_rep = self.query_projection(combined_context) # Shape: [B, 256]
        # # ä¸ºMultiheadAttentionå‡†å¤‡Query (éœ€è¦å¢åŠ ä¸€ä¸ªåºåˆ—é•¿åº¦çš„ç»´åº¦)
        # query = query_rep.unsqueeze(1) # Shape: [B, 1, 256]
        # attn_output, attn_weights = self.cross_attention(
        #     query=query,
        #     key=pathway_level_rep,
        #     value=pathway_level_rep
        # ) # attn_output Shape: [B, 1, 256]ï¼Œ attn_weights Shape: [B, 1, num_pathways]

        # cross_modal_rep = attn_output.squeeze(1) # Shape: [B, 256]
        # # # 1. æ‹¼æ¥å¤šæ¨¡æ€çš„è¡¨å¾åšé¢„æµ‹
        # cat_embeddings = torch.cat([gene_level_rep, cross_modal_rep, text_embeddings], dim=1) # Shape: [B, 768]

        # ============ ã€ä¿®æ”¹ã€‘æ”¶é›†è§£é‡Šæ€§æ•°æ®ï¼Œä¸ç›´æ¥ä¿å­˜ ============
        # æå–æ–‡æœ¬attentionæ•°æ®
        attentions = outputs.attentions
        last_layer_attentions = attentions[-1]
        avg_attentions = last_layer_attentions.mean(dim=1).squeeze(0)
        cls_attention_scores = avg_attentions[0, :]
        tokens = self.clinical_bert_tokenizer.convert_ids_to_tokens(text_inputs['input_ids'][0])
        word_tokens, word_scores = self.aggregate_subword_attentions(tokens, cls_attention_scores.cpu().detach())

        # å®šä¹‰åœç”¨è¯å’Œæ ‡ç‚¹ï¼ˆç”¨äºåç»­è¿‡æ»¤ï¼‰
        # stop_words = set(['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your',
        #                  'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her',
        #                  'hers', 'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs',
        #                  'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those',
        #                  'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had',
        #                  'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if',
        #                  'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with',
        #                  'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after',
        #                  'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over',
        #                  'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where',
        #                  'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other',
        #                  'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too',
        #                  'very', 's', 't', 'can', 'will', 'just', 'don', 'should', 'now'])

        stop_words = set(['I'])

        import string
        punctuation = set(string.punctuation)

        # æå–pathway attentionæ•°æ®ï¼ˆåšä¿®æ”¹0117ï¼‰
        #pathway_names = self.pathway_encoder.hypergraph_structure['pathways']
        #sample_attn_weights = attn_weights[0].squeeze()  # Shape: [num_pathways]
        # === [ä¿®æ”¹] å®‰å…¨è·å–é€šè·¯è§£é‡Šæ•°æ® ===
        if use_pathway and attn_weights is not None:
            pathway_names = self.pathway_encoder.hypergraph_structure['pathways']
            sample_attn_weights = attn_weights[0].squeeze()
        else:
            # å¦‚æœæ²¡ç”¨é€šè·¯ï¼Œç»™ç©ºåˆ—è¡¨ï¼Œé˜²æ­¢æŠ¥é”™
            pathway_names = []
            sample_attn_weights = torch.tensor([])

        # ã€ä¿®æ”¹ã€‘å°†è§£é‡Šæ•°æ®æ‰“åŒ…æˆå­—å…¸ï¼Œä¾›core_util.pyä½¿ç”¨
        explanation_data = {
            'word_tokens': word_tokens,
            'word_scores': word_scores,
            'stop_words': stop_words,
            'punctuation': punctuation,
            'pathway_names': pathway_names,
            'pathway_attention_weights': sample_attn_weights,
            # ã€å·²æ”¹ã€‘æ·»åŠ é—¨æ§èåˆæƒé‡åˆ°è§£é‡Šæ•°æ®
            'survival_gate_weights': survival_gate_weights if 'survival_gate_weights' in locals() else None,
            'stage_gate_weights': stage_gate_weights if self.enable_multitask and 'stage_gate_weights' in locals() else None
        }
        # =========================================



        # ã€ä¿®å¤ã€‘æ ¹æ®è¿è¡Œæ¨¡å¼é€‰æ‹©æ­£ç¡®çš„è¾“å…¥ç‰¹å¾
        if self.ab_model == 1:  # ä»…æ–‡æœ¬æ¨¡å¼
            cat_embeddings = text_embeddings
            # ä»…åœ¨ç¬¬ä¸€ä¸ªbatchæ‰“å°ï¼Œé¿å…æ—¥å¿—åˆ·å±
            if not hasattr(self, '_print_debug'):
                print(f"[Debug] ä»…æ–‡æœ¬æ¨¡å¼: cat_embeddings shape = {cat_embeddings.shape}")
                self._print_debug = True
        elif self.ab_model == 2:  # ä»…åŸºå› æ¨¡å¼
            cat_embeddings = gene_level_rep
            # ä»…åœ¨ç¬¬ä¸€ä¸ªbatchæ‰“å°ï¼Œé¿å…æ—¥å¿—åˆ·å±
            if not hasattr(self, '_print_debug'):
                print(f"[Debug] ä»…åŸºå› æ¨¡å¼: cat_embeddings shape = {cat_embeddings.shape}")
                self._print_debug = True
        else:  # å¤šæ¨¡æ€èåˆæ¨¡å¼ (ab_model == 3)
            if self.use_pathway:
                # å¤šæ¨¡æ€ï¼šåŸºå›  + äº¤å‰æ³¨æ„åŠ› + æ–‡æœ¬
                cat_embeddings = torch.cat([gene_level_rep, cross_modal_rep, text_embeddings], dim=1)
            else:
                # å¤šæ¨¡æ€ï¼šåŸºå›  + æ–‡æœ¬
                cat_embeddings = torch.cat([gene_level_rep, text_embeddings], dim=1)
            # ä»…åœ¨ç¬¬ä¸€ä¸ªbatchæ‰“å°ï¼Œé¿å…æ—¥å¿—åˆ·å±
            if not hasattr(self, '_print_debug'):
                print(f"[Debug] å¤šæ¨¡æ€æ¨¡å¼: cat_embeddings shape = {cat_embeddings.shape}")
                self._print_debug = True

        # ã€å·²æ”¹ã€‘ä¸´æ—¶ç¦ç”¨é—¨æ§èåˆï¼Œæ¢å¤ç®€å•ç›¸åŠ 
        text_pred = self.text_classifier(self.text_projection(text_embeddings))
        gene_pred = self.gene_classifier(gene_level_rep)

        # Survival prediction - ä½¿ç”¨é€‰æ‹©çš„ç‰¹å¾è¿›è¡Œé¢„æµ‹
        survival_logits = self.survival_classifier(cat_embeddings)

        assert len(survival_logits.shape) == 2 and survival_logits.shape[1] == self.n_classes

        if self.use_debias:
        # TE 
            logit_te = self.fusion(survival_logits, text_pred, gene_pred,
                                    main_fact=True, text_fact=True, gene_fact=False)
            logits_nde = self.fusion(survival_logits.clone().detach(), text_pred.clone().detach(), gene_pred,
                                main_fact=False, text_fact=True, gene_fact=False) # NDE
            if self.weight_debiase: # æŒ‡å®š å»åå¼ºåº¦
                logits_tie = logit_te - self.weight_debiase * logits_nde
            else: # å¯å­¦ä¹ çš„å»åå¼ºåº¦
                nde_weight = torch.sigmoid(self.debiase_weight)
                logits_tie = logit_te - nde_weight * logits_nde
            
            logits_text = text_pred
        if self.enable_multitask:
            # Stage prediction - æ ¹æ®è¿è¡Œæ¨¡å¼é€‰æ‹©æ­£ç¡®çš„è¾“å…¥ç‰¹å¾
            if self.ab_model == 1:  # ä»…æ–‡æœ¬æ¨¡å¼
                stage_input = text_embeddings
                print(f"[Debug] ä»…æ–‡æœ¬æ¨¡å¼(Stage): stage_input shape = {stage_input.shape}")
            elif self.ab_model == 2:  # ä»…åŸºå› æ¨¡å¼
                stage_input = gene_level_rep
                print(f"[Debug] ä»…åŸºå› æ¨¡å¼(Stage): stage_input shape = {stage_input.shape}")
            else:  # å¤šæ¨¡æ€èåˆæ¨¡å¼ (ab_model == 3)
                stage_input = torch.cat((gene_level_rep, text_embeddings), dim=1)
                print(f"[Debug] å¤šæ¨¡æ€æ¨¡å¼(Stage): stage_input shape = {stage_input.shape}")

            # è¾“å…¥è¿›åˆ†ç±»å™¨
            stage_logits = self.stage_classifier(stage_input)
            assert len(stage_logits.shape) == 2 and stage_logits.shape[1] == self.n_stage_classes
            #logits_text_stage = self.stage_classifier_text(text_embeddings)
            if 'outputs' in locals():
                raw_bert_cls = outputs.last_hidden_state[:, 0, :] # Shape: [Batch, 768]
                logits_text_stage = self.stage_classifier_text(raw_bert_cls)
            else:
                # ä¸‡ä¸€ outputs ä¸å­˜åœ¨ (ç†è®ºä¸Šä¸ä¼š)ï¼Œå›é€€åˆ°æ—§é€»è¾‘
                logits_text_stage = self.stage_classifier_text(text_embeddings)
        else:
            stage_logits = None

        # ã€ä¿®æ”¹ã€‘æ‰€æœ‰è¿”å›å€¼åé¢éƒ½æ·»åŠ explanation_data
        if self.use_debias and self.enable_multitask and not self.use_align_loss:
            return survival_logits, stage_logits, logits_text, logit_te, logits_tie, logits_nde, explanation_data
        if not self.use_debias and self.enable_multitask:
            return survival_logits, stage_logits, explanation_data
        if not self.use_debias and not self.enable_multitask:
            return survival_logits, explanation_data
        if self.use_debias and self.enable_multitask and self.use_align_loss:
            return survival_logits, stage_logits, logits_text, logit_te, logits_tie, logits_nde, cos_align_loss, explanation_data
        if self.use_debias and not self.enable_multitask:
            return survival_logits, logits_text, logit_te, logits_tie, logits_nde, explanation_data

    def forward_0(self, return_feats=False, **kwargs):
        # print('kwargs: ', kwargs.keys())
        # phrase = kwargs['phrase']
        # ã€åŸºå› çº§åˆ«çš„è¡¨å¾ ï¼Œ é€šè·¯çº§åˆ«çš„è¡¨å¾ï¼Œ æ–‡æœ¬çº§åˆ«çš„è¡¨å¾ã€‘
        x = kwargs['data_omics']
        gene_level_rep = self.fc_omic(x) # 1.åŸºå› çº§åˆ«çš„è¡¨å¾ [1, dim]
        # print('gene_level_rep.shape:', gene_level_rep.shape)

        pathway_level_rep = self.pathway_encoder(x) # 2.é€šè·¯çº§åˆ«çš„è¡¨å¾  [batch_size, num_pathways, dim]
        # print('pathway_level_rep.shape:', pathway_level_rep.shape)
        # pathway_level_rep = pathway_level_rep.

        x_text_report = kwargs['x_text_report'][-1] 
        text_inputs = self.clinical_bert_tokenizer(
            x_text_report, 
            return_tensors="pt", 
            truncation=True, 
            padding=True, 
            max_length=512
        ).to(x.device)
        
        # outputs = self.clinical_bert_model(**text_inputs)
        outputs = self.clinical_bert_model(**text_inputs, output_attentions=True)
        # ä½¿ç”¨ [CLS] token çš„åµŒå…¥
        text_embeddings = outputs.last_hidden_state[:, 0, :] # 3.æ–‡æœ¬çº§åˆ«çš„è¡¨å¾ [batch_size, dim] 
        # print('text_embeddings.shape:', text_embeddings.shape)
        text_embeddings = self.text_projection(text_embeddings) # å˜ä¸º dim
        # print('text_embeddings.shape:', text_embeddings.shape)

        combined_context = torch.cat([gene_level_rep, text_embeddings], dim=1) # Shape: [B, 512]
        query_rep = self.query_projection(combined_context) # Shape: [B, 256]
        # ä¸ºMultiheadAttentionå‡†å¤‡Query (éœ€è¦å¢åŠ ä¸€ä¸ªåºåˆ—é•¿åº¦çš„ç»´åº¦)
        query = query_rep.unsqueeze(1) # Shape: [B, 1, 256]
        attn_output, attn_weights = self.cross_attention(
            query=query,
            key=pathway_level_rep,
            value=pathway_level_rep
        ) # attn_output Shape: [B, 1, 256]ï¼Œ attn_weights Shape: [B, 1, num_pathways]

        cross_modal_rep = attn_output.squeeze(1) # Shape: [B, 256]
        # # 1. æ‹¼æ¥å¤šæ¨¡æ€çš„è¡¨å¾åšé¢„æµ‹
        cat_embeddings = torch.cat([gene_level_rep, cross_modal_rep, text_embeddings], dim=1) # Shape: [B, 768]
        # print('cat_embeddings.shape:', cat_embeddings.shape)

        # # 2. ç›´æ¥ç”¨ cross_modal_rep åšé¢„æµ‹
        # cat_embeddings = cross_modal_rep
        # survival_logits = self.survival_classifier(cat_embeddings)

        # 3. æ®‹å·® é“¾æ¥å¤šæ¨¡æ€
        # cat_embeddings = cross_modal_rep + gene_level_rep + text_embeddings
        # survival_logits = self.survival_classifier(cat_embeddings)




        # if phrase == 'test':
        print('test mode')
        attentions = outputs.attentions 
        last_layer_attentions = attentions[-1]
        avg_attentions = last_layer_attentions.mean(dim=1).squeeze(0)
        cls_attention_scores = avg_attentions[0, :]
        tokens = self.clinical_bert_tokenizer.convert_ids_to_tokens(text_inputs['input_ids'][0])
        word_tokens, word_scores = self.aggregate_subword_attentions(tokens, cls_attention_scores.cpu().detach())

        stop_words = set(['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers', 'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'should', 'now'])

        punctuation = set(string.punctuation)

        filtered_words = []
        filtered_scores = []
        
        for word, score in zip(word_tokens, word_scores):
            # è¿‡æ»¤æ¡ä»¶ï¼šå•è¯å°å†™åä¸åœ¨åœç”¨è¯åˆ—è¡¨ï¼Œä¸”å•è¯æœ¬èº«ä¸åœ¨æ ‡ç‚¹ç¬¦å·åˆ—è¡¨
            if word.lower() not in stop_words and word not in punctuation:
                filtered_words.append(word)
                filtered_scores.append(score.item()) # .item() å°†0ç»´å¼ é‡è½¬ä¸ºæ•°å­—
        # --- è¿‡æ»¤ç»“æŸ ---


        # æ‰“å°æœ€é‡è¦çš„Top-15ä¸ªã€ç»è¿‡æ»¤çš„å®Œæ•´å•è¯ã€‘
        import pandas as pd
        df = pd.DataFrame({'word': filtered_words, 'attention': filtered_scores})
        df = df.sort_values(by='attention', ascending=False)
        # print("\n--- [æ¨¡å‹æ–‡æœ¬è§£é‡Š (å·²è¿‡æ»¤)] ---")
        # print("Top 15 Most Attended Keywords:")
        # print(df.head(15))
        # print("-------------------------------------\n")

        # 9. ç”Ÿæˆé«˜äº®æ–‡æœ¬è¿›è¡Œå¯è§†åŒ– (åŸºäºå®Œæ•´å•è¯)
        # self.visualize_keywords_in_context(word_tokens, word_scores, stop_words, punctuation)


        pathway_names = self.pathway_encoder.hypergraph_structure['pathways']
        sample_attn_weights = attn_weights[0].squeeze() # å½¢çŠ¶å˜ä¸º [num_pathways]
        
        # è°ƒç”¨å¯è§†åŒ–å‡½æ•°
        self.visualize_top_pathways(sample_attn_weights, pathway_names, top_k=15)

        
        if self.only_omic:
            # h_omic = self.fc_omic(x)
            # cat_embeddings = h_omic
            cat_embeddings = gene_level_rep
        if self.only_text:
            cat_embeddings = text_embeddings
        
        # Survival prediction
        # cat_embeddings = self.dropout_omic(cat_embeddings)

        survival_logits = self.survival_classifier(cat_embeddings)
        
        # survival_logits = self.survival_classifier(h_omic)
        assert len(survival_logits.shape) == 2 and survival_logits.shape[1] == self.n_classes
        text_pred = self.text_classifier(text_embeddings)
        gene_pred = self.gene_classifier(gene_level_rep)
        
        if self.use_debias:
        # TE 
            logit_te = self.fusion(survival_logits, text_pred, gene_pred,
                                    main_fact=True, text_fact=True, gene_fact=False)
            # logits_text = self.fusion(survival_logits, text_pred, gene_pred,
            #                     main_fact=False, text_fact=True, gene_fact=False) 
            logits_nde = self.fusion(survival_logits.clone().detach(), text_pred.clone().detach(), gene_pred,
                                main_fact=False, text_fact=True, gene_fact=False) # NDE
            if self.weight_debiase: # æŒ‡å®š å»åå¼ºåº¦
                logits_tie = logit_te - self.weight_debiase * logits_nde
            else: # å¯å­¦ä¹ çš„å»åå¼ºåº¦
                nde_weight = torch.sigmoid(self.debiase_weight)
                logits_tie = logit_te - nde_weight * logits_nde
            
            logits_text = text_pred
            # nde_weight æ˜¯é€šè¿‡ text_embeddings å¾—åˆ°çš„ä¸€ä¸ªå¯å­¦ä¹ å‚æ•°
            # nde_weight = torch.sigmoid(self.lin_weight(text_embeddings))
            # logits_tie = logit_te - nde_weight * logits_nde
                
        if self.enable_multitask:
            # Stage prediction
            stage_logits = self.stage_classifier(cat_embeddings)
            assert len(stage_logits.shape) == 2 and stage_logits.shape[1] == self.n_stage_classes
            logits_text_stage = self.text_classifier_stage(text_embeddings)
            # gene_logits_stage = self.gene_classifier_stage(h_omic)
            # logit_te_stage = self.fusion_stage(stage_logits, text_logits_stage, gene_logits_stage,
            #                                     main_fact=True, text_fact=True, gene_fact=False)
            # logits_nde_stage = self.fusion_stage(stage_logits.clone().detach(), text_logits_stage.clone().detach(), gene_logits_stage,
            #                                     main_fact=False, text_fact=True, gene_fact=False) # NDE
            # nde_weight_stage2 = torch.sigmoid(self.debiase_weight2)
            # logit_te_stage = logit_te_stage + nde_weight_stage2 * logits_nde_stage
            
        else:
            stage_logits = None
            
        if self.use_debias and self.enable_multitask and not self.use_align_loss:
            return survival_logits, stage_logits, logits_text, logit_te, logits_tie, logits_nde
        if not self.use_debias and self.enable_multitask:
            return survival_logits, stage_logits
        if not self.use_debias and not self.enable_multitask:
            return survival_logits
        if self.use_debias and self.enable_multitask and self.use_align_loss:
            # print('return survival_logits, stage_logits, logits_text, logit_te, logits_tie, logits_nde, cos_align_loss: ')
            return survival_logits, stage_logits, logits_text, logit_te, logits_tie, logits_nde, cos_align_loss
        if self.use_debias and not self.enable_multitask:
            return survival_logits, logits_text, logit_te, logits_tie, logits_nde
    
    def forward00(self, return_feats=False, **kwargs):
        x = kwargs['data_omics']
        # print('x shape: ', x.shape)
        Hy_gen = self.pathway_encoder(x) # [num_gen, hidden_dim=1]
        # print('Hy_gen.shape:', Hy_gen.shape)
        x_text_report = kwargs['x_text_report'][-1]
        text_inputs = self.clinical_bert_tokenizer(
            x_text_report, 
            return_tensors="pt", 
            truncation=True, 
            padding=True, 
            max_length=512
        ).to(x.device)
        
        outputs = self.clinical_bert_model(**text_inputs)
        # ä½¿ç”¨ [CLS] token çš„åµŒå…¥
        text_embeddings = outputs.last_hidden_state[:, 0, :] # [batch_size, hidden_dim]
        
        hint_emb = Hy_gen
        
        # æ®‹å·®
        if self.use_resnet:
            hint_emb = hint_emb + x
        hint_emb = self.fc_omic(hint_emb)
        if self.NOT_hygraph:
            # ç›´æ¥å°†åŸå§‹çš„ x è¾“å…¥ SNN ï¼Œå¾—åˆ° hint_emb
            hint_emb = self.fc_omic(x)
        # hint_emb = self.dropout_omic(hint_emb)
        
        if self.use_align_loss:
            # text_embeddings_align = self.lin_text_emb(text_embeddings)
            cos_align_loss = self.alignment_model.alignment_loss(hint_emb, text_embeddings)
            aligned_gene, aligned_wsi = self.alignment_model.forward(hint_emb, text_embeddings)
            hint_emb = aligned_gene 
            text_embeddings = aligned_wsi
        cat_embeddings = torch.cat((hint_emb, text_embeddings), dim=1)
        if self.only_omic:
            # h_omic = self.fc_omic(x)
            # cat_embeddings = h_omic
            cat_embeddings = hint_emb
        if self.only_text:
            cat_embeddings = text_embeddings
        
        # Survival prediction
        # cat_embeddings = self.dropout_omic(cat_embeddings)
        survival_logits = self.survival_classifier(cat_embeddings)
        
        # survival_logits = self.survival_classifier(h_omic)
        assert len(survival_logits.shape) == 2 and survival_logits.shape[1] == self.n_classes
        text_pred = self.text_classifier(text_embeddings)
        gene_pred = self.gene_classifier(hint_emb)
        
        if self.use_debias:
        # TE 
            logit_te = self.fusion(survival_logits, text_pred, gene_pred,
                                    main_fact=True, text_fact=True, gene_fact=False)
            # logits_text = self.fusion(survival_logits, text_pred, gene_pred,
            #                     main_fact=False, text_fact=True, gene_fact=False) 
            logits_nde = self.fusion(survival_logits.clone().detach(), text_pred.clone().detach(), gene_pred,
                                main_fact=False, text_fact=True, gene_fact=False) # NDE
            if self.weight_debiase: # æŒ‡å®š å»åå¼ºåº¦
                logits_tie = logit_te - self.weight_debiase * logits_nde
            else: # å¯å­¦ä¹ çš„å»åå¼ºåº¦
                nde_weight = torch.sigmoid(self.debiase_weight)
                logits_tie = logit_te - nde_weight * logits_nde
            
            logits_text = text_pred
            # nde_weight æ˜¯é€šè¿‡ text_embeddings å¾—åˆ°çš„ä¸€ä¸ªå¯å­¦ä¹ å‚æ•°
            # nde_weight = torch.sigmoid(self.lin_weight(text_embeddings))
            # logits_tie = logit_te - nde_weight * logits_nde
                
        if self.enable_multitask:
            # Stage prediction
            stage_logits = self.stage_classifier(cat_embeddings)
            assert len(stage_logits.shape) == 2 and stage_logits.shape[1] == self.n_stage_classes
            logits_text_stage = self.text_classifier_stage(text_embeddings)
            # gene_logits_stage = self.gene_classifier_stage(h_omic)
            # logit_te_stage = self.fusion_stage(stage_logits, text_logits_stage, gene_logits_stage,
            #                                     main_fact=True, text_fact=True, gene_fact=False)
            # logits_nde_stage = self.fusion_stage(stage_logits.clone().detach(), text_logits_stage.clone().detach(), gene_logits_stage,
            #                                     main_fact=False, text_fact=True, gene_fact=False) # NDE
            # nde_weight_stage2 = torch.sigmoid(self.debiase_weight2)
            # logit_te_stage = logit_te_stage + nde_weight_stage2 * logits_nde_stage
            
        else:
            stage_logits = None
            
        if self.use_debias and self.enable_multitask and not self.use_align_loss:
            return survival_logits, stage_logits, logits_text, logit_te, logits_tie, logits_nde
        if not self.use_debias and self.enable_multitask:
            return survival_logits, stage_logits
        if not self.use_debias and not self.enable_multitask:
            return survival_logits
        if self.use_debias and self.enable_multitask and self.use_align_loss:
            # print('return survival_logits, stage_logits, logits_text, logit_te, logits_tie, logits_nde, cos_align_loss: ')
            return survival_logits, stage_logits, logits_text, logit_te, logits_tie, logits_nde, cos_align_loss
        if self.use_debias and not self.enable_multitask:
            return survival_logits, logits_text, logit_te, logits_tie, logits_nde
    def relocate(self):
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

        if torch.cuda.device_count() > 1:
            device_ids = list(range(torch.cuda.device_count()))
            self.fc_omic = nn.DataParallel(self.fc_omic, device_ids=device_ids).to('cuda:0')
        else:
            self.fc_omic = self.fc_omic.to(device)

        self.survival_classifier = self.survival_classifier.to(device)
        if self.enable_multitask:
            self.stage_classifier = self.stage_classifier.to(device)


def init_max_weights(module):
    r"""
    Initialize Weights function.

    args:
        modules (torch.nn.Module): Initalize weight using normal distribution
    """
    import math
    import torch.nn as nn
    
    for m in module.modules():
        if type(m) == nn.Linear:
            stdv = 1. / math.sqrt(m.weight.size(1))
            m.weight.data.normal_(0, stdv)
            m.bias.data.zero_()