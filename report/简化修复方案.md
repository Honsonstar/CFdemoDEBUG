# 数据泄露修复方案 (基因+文本特征专用)

## 核心思路

专注于两种特征类型：
1. **基因特征**: 从CPCG筛选得到
2. **文本特征**: 从病理报告提取

避免复杂的多模态特征，简化流程。

## 方案概述

### 当前错误流程 (泄露)
```
整个数据集 → CPCG筛选基因 → 5折CV
              ↑ 泄露点
```

### 正确流程 (无泄露)
```
5折CV
├─ Fold1: Train做CPCG → 筛选基因 → 训练/验证/测试
├─ Fold2: Train做CPCG → 筛选基因 → 训练/验证/测试
├─ Fold3: Train做CPCG → 筛选基因 → 训练/验证/测试
├─ Fold4: Train做CPCG → 筛选基因 → 训练/验证/测试
└─ Fold5: Train做CPCG → 筛选基因 → 训练/验证/测试
```

## 具体实施步骤

### 步骤1: 修改数据划分

创建嵌套CV划分文件，包含train/val/test样本ID

```python
# 工具脚本: create_nested_splits.py
import pandas as pd
import numpy as np
from sklearn.model_selection import StratifiedKFold, train_test_split

def create_nested_splits(clinical_file, output_dir, n_splits=5):
    """创建嵌套CV划分"""
    df = pd.read_csv(clinical_file)
    ids = df['case_id'].values
    labels = df['censorship'].values
    
    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)
    
    for fold, (train_val_idx, test_idx) in enumerate(skf.split(ids, labels)):
        # 保存划分
        train_val_ids = ids[train_val_idx]
        test_ids = ids[test_idx]
        
        # 划分训练/验证
        train_idx, val_idx = train_test_split(
            np.arange(len(train_val_ids)),
            test_size=0.15,
            stratify=labels[train_val_idx],
            random_state=42
        )
        
        train_ids = train_val_ids[train_idx]
        val_ids = train_val_ids[val_idx]
        
        # 保存到CSV
        split_df = pd.DataFrame({
            'train': train_ids,
            'val': val_ids,
            'test': test_ids
        })
        split_df.to_csv(f'{output_dir}/nested_splits_{fold}.csv', index=False)
```

### 步骤2: 修改CPCG为按折筛选

```python
# 工具脚本: run_cpog_per_fold.py
import pandas as pd
import os

def run_cpog_for_fold(fold, train_ids, clinical_dir, output_dir):
    """为特定折运行CPCG特征筛选"""
    
    # 加载训练集数据
    clinical_file = f'{clinical_dir}/tcga_blca_clinical.csv'
    df = pd.read_csv(clinical_file)
    
    # 筛选训练集样本
    train_mask = df['case_id'].isin(train_ids)
    train_df = df[train_mask].copy()
    
    # 运行CPCG (仅在训练集上)
    # ... 调用CPCG算法 ...
    
    # 保存筛选的基因列表
    genes = [...]  # CPCG筛选结果
    gene_df = pd.DataFrame({'gene': genes})
    gene_df.to_csv(f'{output_dir}/fold_{fold}_genes.csv', index=False)
    
    return genes

# 主流程
for fold in range(5):
    splits = pd.read_csv(f'splits/nested_splits_{fold}.csv')
    train_ids = splits['train'].dropna().tolist()
    
    genes = run_cpog_for_fold(
        fold=fold,
        train_ids=train_ids,
        clinical_dir='datasets_csv/clinical_data',
        output_dir='features'
    )
```

### 步骤3: 修改数据加载器

```python
# datasets/dataset_survival.py (关键修改)

class SurvivalDatasetFactory:
    def __init__(self, ..., use_nested_cv=False, fold=0):
        # ... 原有初始化 ...
        self.use_nested_cv = use_nested_cv
        self.fold = fold
        
    def _setup_omics_data(self):
        if self.use_nested_cv:
            # 加载该折筛选的基因
            gene_file = f'features/fold_{self.fold}_genes.csv'
            selected_genes = pd.read_csv(gene_file)['gene'].tolist()
            
            # 加载完整表达数据
            full_data = pd.read_csv('datasets_csv/raw_rna_data/xena/blca/rna_clean.csv', index_col=0)
            
            # 筛选指定基因
            available_genes = [g for g in selected_genes if g in full_data.columns]
            self.rna_data = full_data[available_genes]
            
            print(f"[Fold {self.fold}] 使用 {len(available_genes)} 个筛选基因")
        else:
            # 原有逻辑 (全局CPCG特征)
            ...
```

### 步骤4: 修改训练脚本

```python
# main.py (关键修改)

def main():
    # 1. 创建嵌套CV划分 (如果不存在)
    if not os.path.exists('splits/nested_cv'):
        create_nested_splits(...)
    
    # 2. 为每折运行CPCG筛选
    for fold in range(5):
        splits = pd.read_csv(f'splits/nested_cv/nested_splits_{fold}.csv')
        train_ids = splits['train'].dropna().tolist()
        run_cpog_for_fold(fold, train_ids, ...)
    
    # 3. 训练每折
    for fold in range(5):
        # 设置嵌套CV模式
        args.use_nested_cv = True
        args.fold = fold
        
        # 创建数据集工厂
        dataset_factory = SurvivalDatasetFactory(
            ...,
            use_nested_cv=True,
            fold=fold
        )
        
        # 加载该折的数据划分
        csv_path = f'splits/nested_cv/nested_splits_{fold}.csv'
        datasets = dataset_factory.return_splits(csv_path, fold)
        
        # 训练和评估
        results = _train_val_with_km_plots(datasets, fold, args)
        
        # 保存结果
        save_results(results, fold)
```

## 快速实施脚本

### 脚本1: 一键创建嵌套CV划分

```bash
#!/bin/bash
# scripts/create_nested_splits.sh

STUDY=$1
if [ -z "$STUDY" ]; then
    echo "用法: bash create_nested_splits.sh <study>"
    echo "例: bash create_nested_splits.sh blca"
    exit 1
fi

python - << PYTHON
import pandas as pd
import numpy as np
from sklearn.model_selection import StratifiedKFold, train_test_split

clinical_file = f'datasets_csv/clinical_data/tcga_{STUDY}_clinical.csv'
output_dir = f'splits/nested_cv/{STUDY}'

df = pd.read_csv(clinical_file)
ids = df['case_id'].values
labels = df['censorship'].values

skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

os.makedirs(output_dir, exist_ok=True)

for fold, (train_val_idx, test_idx) in enumerate(skf.split(ids, labels)):
    train_val_ids = ids[train_val_idx]
    test_ids = ids[test_idx]
    
    train_idx, val_idx = train_test_split(
        np.arange(len(train_val_ids)),
        test_size=0.15,
        stratify=labels[train_val_idx],
        random_state=42
    )
    
    train_ids = train_val_ids[train_idx]
    val_ids = train_val_ids[val_idx]
    
    split_df = pd.DataFrame({
        'train': train_ids,
        'val': val_ids,
        'test': test_ids
    })
    split_df.to_csv(f'{output_dir}/nested_splits_{fold}.csv', index=False)
    
    print(f"Fold {fold}: Train={len(train_ids)}, Val={len(val_ids)}, Test={len(test_ids)}")

print(f"✓ 嵌套CV划分完成: {output_dir}")
PYTHON
```

### 脚本2: 一键运行CPCG筛选

```bash
#!/bin/bash
# scripts/run_cpog_nested.sh

STUDY=$1
FOLD=$2

if [ -z "$STUDY" ] || [ -z "$FOLD" ]; then
    echo "用法: bash run_cpog_nested.sh <study> <fold>"
    echo "例: bash run_cpog_nested.sh blca 0"
    exit 1
fi

python - << PYTHON
import pandas as pd
import sys

study = '$STUDY'
fold = int('$FOLD')

print(f"开始为 {study} Fold {fold} 运行CPCG...")

# 读取训练集样本
splits_df = pd.read_csv(f'splits/nested_cv/{study}/nested_splits_{fold}.csv')
train_ids = splits_df['train'].dropna().tolist()

print(f"训练集样本数: {len(train_ids)}")

# TODO: 在这里调用CPCG算法
# - 加载训练集临床数据
# - 加载训练集基因表达数据
# - 运行Stage1和Stage2
# - 保存筛选的基因列表

# 示例保存基因列表
genes = ['GENE1', 'GENE2', 'GENE3']  # 替换为实际CPCG结果
gene_df = pd.DataFrame({'gene': genes})
gene_df.to_csv(f'features/{study}/fold_{fold}_genes.csv', index=False)

print(f"✓ Fold {fold} CPCG完成，筛选 {len(genes)} 个基因")
PYTHON
```

### 脚本3: 一键训练 (对比版本)

```bash
#!/bin/bash
# scripts/train_nested_vs_global.sh

STUDY=$1
if [ -z "$STUDY" ]; then
    echo "用法: bash train_nested_vs_global.sh <study>"
    echo "例: bash train_nested_vs_global.sh blca"
    exit 1
fi

echo "=== 对比实验: 嵌套CV vs 全局CV ==="

# 1. 全局CPCG (错误方法)
echo "\n1. 运行全局CPCG (错误方法)..."
python main.py \
    --study tcga_${STUDY} \
    --label_file datasets_csv/clinical_data/tcga_${STUDY}_clinical.csv \
    --omics_dir preprocessing/CPCG_algo/raw_data/finalstage_result_/tcga_${STUDY}/tcga_${STUDY}_M2M3base_0916.csv \
    --results_dir results_global_cv \
    --which_splits 5foldcv \
    --k 5 \
    --seed 1 \
    2>&1 | tee results_global_cv.log

# 2. 嵌套CV (正确方法)
echo "\n2. 运行嵌套CV (正确方法)..."
python main_nested.py \
    --study tcga_${STUDY} \
    --label_file datasets_csv/clinical_data/tcga_${STUDY}_clinical.csv \
    --results_dir results_nested_cv \
    --use_nested_cv \
    --k 5 \
    --seed 1 \
    2>&1 | tee results_nested_cv.log

# 3. 对比结果
echo "\n3. 对比结果..."
python - << PYTHON
import pandas as pd
import numpy as np

# 读取全局CV结果
global_df = pd.read_csv('results_global_cv/summary.csv')
print("全局CV (泄露):")
print(f"  平均C-index: {global_df['val_cindex'].mean():.4f} ± {global_df['val_cindex'].std():.4f}")

# 读取嵌套CV结果
nested_df = pd.read_csv('results_nested_cv/summary.csv')
print("\n嵌套CV (正确):")
print(f"  平均C-index: {nested_df['val_cindex'].mean():.4f} ± {nested_df['val_cindex'].std():.4f}")

# 计算性能下降
drop = global_df['val_cindex'].mean() - nested_df['val_cindex'].mean()
print(f"\n性能下降: {drop:.4f} ({drop/global_df['val_cindex'].mean()*100:.1f}%)")
PYTHON

echo "\n✓ 对比实验完成!"
```

## 预期结果

### 性能对比 (预期)

| 方法 | C-index | IPCW | IBS | 风险等级 |
|------|---------|------|-----|----------|
| 全局CPCG (错误) | 0.75 ± 0.02 | 0.70 | 0.18 | ★★★★★ 泄露 |
| 嵌套CV (正确) | 0.62 ± 0.05 | 0.58 | 0.25 | ★★ 可信 |
| 差异 | -0.13 | -0.12 | +0.07 | - |

### 统计显著性

```python
# McNemar检验
from scipy.stats import mcnemar

global_preds = [...]  # 全局CV预测结果
nested_preds = [...]  # 嵌套CV预测结果

contingency_table = [[a, b], [c, d]]
result = mcnemar(contingency_table, exact=False)
print(f"p-value: {result.pvalue}")

if result.pvalue < 0.05:
    print("性能差异统计显著 (p < 0.05)")
else:
    print("性能差异不显著 (p >= 0.05)")
```

## 关键修改文件清单

### 需要创建的文件

1. `scripts/create_nested_splits.sh` - 创建嵌套CV划分
2. `scripts/run_cpog_nested.sh` - 按折运行CPCG
3. `scripts/train_nested_vs_global.sh` - 对比实验脚本
4. `utils/nested_cv_utils.py` - 嵌套CV工具函数

### 需要修改的文件

1. `datasets/dataset_survival.py`
   - 添加 `use_nested_cv` 和 `fold` 参数
   - 修改 `_setup_omics_data()` 支持动态基因选择

2. `main.py`
   - 添加嵌套CV训练逻辑
   - 为每折加载对应的基因列表

3. `utils/core_utils.py`
   - 可能需要微调训练流程

## 验证步骤

### 1. 代码验证

```bash
# 验证数据加载
python -c "
from datasets.dataset_survival import SurvivalDatasetFactory
factory = SurvivalDatasetFactory(
    study='tcga_blca',
    label_file='datasets_csv/clinical_data/tcga_blca_clinical.csv',
    use_nested_cv=True,
    fold=0
)
print('✓ 数据加载正常')
"

# 验证特征筛选
python -c "
import pandas as pd
genes = pd.read_csv('features/blca/fold_0_genes.csv')
print(f'✓ 基因数: {len(genes)}')
"
```

### 2. 单元测试

```python
# tests/test_nested_cv.py
import unittest
import pandas as pd
import numpy as np

class TestNestedCV(unittest.TestCase):
    def test_split_creation(self):
        """测试划分创建"""
        splits = pd.read_csv('splits/nested_cv/blca/nested_splits_0.csv')
        self.assertGreater(len(splits['train'].dropna()), 0)
        self.assertGreater(len(splits['val'].dropna()), 0)
        self.assertGreater(len(splits['test'].dropna()), 0)
    
    def test_gene_selection(self):
        """测试基因选择"""
        genes = pd.read_csv('features/blca/fold_0_genes.csv')
        self.assertGreater(len(genes), 10)  # 至少筛选10个基因
        self.assertLess(len(genes), 500)    # 少于500个基因
    
    def test_no_overlap(self):
        """测试不同折的基因差异"""
        genes_f0 = set(pd.read_csv('features/blca/fold_0_genes.csv')['gene'])
        genes_f1 = set(pd.read_csv('features/blca/fold_1_genes.csv')['gene'])
        # 应该有部分重叠，但不应完全相同
        overlap = len(genes_f0 & genes_f1) / len(genes_f0 | genes_f1)
        self.assertGreater(overlap, 0.3)  # 至少30%重叠
        self.assertLess(overlap, 1.0)    # 少于100%重叠

if __name__ == '__main__':
    unittest.main()
```

### 3. 对比实验

运行完整对比实验，验证修复效果。

## 总结

这个简化方案专注于基因和文本特征，避免了复杂的多模态处理。通过嵌套交叉验证，彻底解决数据泄露问题，确保结果可信。

关键优势:
1. ✅ 彻底解决数据泄露
2. ✅ 专注于核心特征 (基因+文本)
3. ✅ 易于实施和验证
4. ✅ 提供对比实验验证效果
