cuda
Split dir: splits/nested_cv/blca

################# Settings ###################
num_splits:  5
k_start:  0
k_end:  1
task:  survival
max_epochs:  2
results_dir:  ./results/test_results/tcga_blca__nll_surv_a0.5_lr5e-05_l2Weight_1e-05_5foldcv_b1_survival_months_dim1_256_patches_4096_wsiDim_256_epochs_2_fusion_None_modality_snn_pathT_combine
lr:  5e-05
experiment:  tcga_blca
reg:  1e-05
bag_loss:  nll_surv
seed:  42
weighted_sample:  True
opt:  adam
num_patches:  4096
dropout:  0.25
type_of_path:  combine
split_dir:  splits/nested_cv/blca
enable_multitask:  False
multitask_weight:  0.3

Loaded clinical data from: ./datasets_csv/clinical_data/tcga_blca_clinical.csv
Clinical data shape: (423, 13)
Clinical data index (case_id) samples: ['TCGA-2F-A9KO', 'TCGA-2F-A9KP', 'TCGA-2F-A9KP', 'TCGA-2F-A9KQ', 'TCGA-2F-A9KR']
Available stages: stage
III        190
II          94
unknown     77
IV          59
I            3
Name: count, dtype: int64
label column: survival_months
number of cases 359
number of classes: 8
Using nested CV splits: splits/nested_cv/blca/nested_splits_0.csv
Defining datasets...
Using split_key='val' for validation set.
Created train and val datasets for fold 0

Training Fold 0!

Init train/val splits... 
Done!
Training on 253 samples
Validating on 50 samples

Init loss function... Done!

Init Model... üöÄ [Init Model] ËøêË°åÊ®°Âºè: 3 (Â§öÊ®°ÊÄÅËûçÂêà)
üöÄ [Model Config] ËøêË°åÊ®°Âºè: 3 (Â§öÊ®°ÊÄÅËûçÂêà)
üîÑ ‰ªéÁºìÂ≠òÂä†ËΩΩË∂ÖÂõæÁªìÊûÑ: hypergraph_cache/hypergraph_structure_30ec1ddd135fba505bc72e6c33fed21e.pkl
‚úÖ ÁºìÂ≠òÂä†ËΩΩÊàêÂäü!

==============================
Model: snn
ÊÄªÂèÇÊï∞Èáè (Total):      0.1115 B
ÂèØËÆ≠ÁªÉÂèÇÊï∞ (Trainable): 0.1115 B
==============================


Detailed layer-by-layer parameters:
Layer:                                                    | Params: 3
Layer: pathway_encoder.hypergraph_convs.0                 | Params: 128
Layer: pathway_encoder.hypergraph_convs.0.lin             | Params: 128
Layer: pathway_encoder.hypergraph_convs.1                 | Params: 256
Layer: pathway_encoder.hypergraph_convs.1.lin             | Params: 32,768
Layer: pathway_encoder.layer_norms.0                      | Params: 256
Layer: pathway_encoder.layer_norms.1                      | Params: 512
Layer: pathway_encoder.pathway_self_attention             | Params: 197,376
Layer: pathway_encoder.pathway_self_attention.out_proj    | Params: 65,792
Layer: pathway_encoder.feature_fusion.0                   | Params: 131,328
Layer: pathway_encoder.feature_fusion.2                   | Params: 512
Layer: pathway_encoder.output_projection                  | Params: 65,792
Layer: cross_attention                                    | Params: 197,376
Layer: cross_attention.out_proj                           | Params: 65,792
Layer: query_projection                                   | Params: 131,328
Layer: clinical_bert_model.embeddings.word_embeddings     | Params: 22,268,928
Layer: clinical_bert_model.embeddings.position_embeddings | Params: 393,216
Layer: clinical_bert_model.embeddings.token_type_embeddings | Params: 1,536
Layer: clinical_bert_model.embeddings.LayerNorm           | Params: 1,536
Layer: clinical_bert_model.encoder.layer.0.attention.self.query | Params: 590,592
Layer: clinical_bert_model.encoder.layer.0.attention.self.key | Params: 590,592
Layer: clinical_bert_model.encoder.layer.0.attention.self.value | Params: 590,592
Layer: clinical_bert_model.encoder.layer.0.attention.output.dense | Params: 590,592
Layer: clinical_bert_model.encoder.layer.0.attention.output.LayerNorm | Params: 1,536
Layer: clinical_bert_model.encoder.layer.0.intermediate.dense | Params: 2,362,368
Layer: clinical_bert_model.encoder.layer.0.output.dense   | Params: 2,360,064
Layer: clinical_bert_model.encoder.layer.0.output.LayerNorm | Params: 1,536
Layer: clinical_bert_model.encoder.layer.1.attention.self.query | Params: 590,592
Layer: clinical_bert_model.encoder.layer.1.attention.self.key | Params: 590,592
Layer: clinical_bert_model.encoder.layer.1.attention.self.value | Params: 590,592
Layer: clinical_bert_model.encoder.layer.1.attention.output.dense | Params: 590,592
Layer: clinical_bert_model.encoder.layer.1.attention.output.LayerNorm | Params: 1,536
Layer: clinical_bert_model.encoder.layer.1.intermediate.dense | Params: 2,362,368
Layer: clinical_bert_model.encoder.layer.1.output.dense   | Params: 2,360,064
Layer: clinical_bert_model.encoder.layer.1.output.LayerNorm | Params: 1,536
Layer: clinical_bert_model.encoder.layer.2.attention.self.query | Params: 590,592
Layer: clinical_bert_model.encoder.layer.2.attention.self.key | Params: 590,592
Layer: clinical_bert_model.encoder.layer.2.attention.self.value | Params: 590,592
Layer: clinical_bert_model.encoder.layer.2.attention.output.dense | Params: 590,592
Layer: clinical_bert_model.encoder.layer.2.attention.output.LayerNorm | Params: 1,536
Layer: clinical_bert_model.encoder.layer.2.intermediate.dense | Params: 2,362,368
Layer: clinical_bert_model.encoder.layer.2.output.dense   | Params: 2,360,064
Layer: clinical_bert_model.encoder.layer.2.output.LayerNorm | Params: 1,536
Layer: clinical_bert_model.encoder.layer.3.attention.self.query | Params: 590,592
Layer: clinical_bert_model.encoder.layer.3.attention.self.key | Params: 590,592
Layer: clinical_bert_model.encoder.layer.3.attention.self.value | Params: 590,592
Layer: clinical_bert_model.encoder.layer.3.attention.output.dense | Params: 590,592
Layer: clinical_bert_model.encoder.layer.3.attention.output.LayerNorm | Params: 1,536
Layer: clinical_bert_model.encoder.layer.3.intermediate.dense | Params: 2,362,368
Layer: clinical_bert_model.encoder.layer.3.output.dense   | Params: 2,360,064
Layer: clinical_bert_model.encoder.layer.3.output.LayerNorm | Params: 1,536
Layer: clinical_bert_model.encoder.layer.4.attention.self.query | Params: 590,592
Layer: clinical_bert_model.encoder.layer.4.attention.self.key | Params: 590,592
Layer: clinical_bert_model.encoder.layer.4.attention.self.value | Params: 590,592
Layer: clinical_bert_model.encoder.layer.4.attention.output.dense | Params: 590,592
Layer: clinical_bert_model.encoder.layer.4.attention.output.LayerNorm | Params: 1,536
Layer: clinical_bert_model.encoder.layer.4.intermediate.dense | Params: 2,362,368
Layer: clinical_bert_model.encoder.layer.4.output.dense   | Params: 2,360,064
Layer: clinical_bert_model.encoder.layer.4.output.LayerNorm | Params: 1,536
Layer: clinical_bert_model.encoder.layer.5.attention.self.query | Params: 590,592
Layer: clinical_bert_model.encoder.layer.5.attention.self.key | Params: 590,592
Layer: clinical_bert_model.encoder.layer.5.attention.self.value | Params: 590,592
Layer: clinical_bert_model.encoder.layer.5.attention.output.dense | Params: 590,592
Layer: clinical_bert_model.encoder.layer.5.attention.output.LayerNorm | Params: 1,536
Layer: clinical_bert_model.encoder.layer.5.intermediate.dense | Params: 2,362,368
Layer: clinical_bert_model.encoder.layer.5.output.dense   | Params: 2,360,064
Layer: clinical_bert_model.encoder.layer.5.output.LayerNorm | Params: 1,536
Layer: clinical_bert_model.encoder.layer.6.attention.self.query | Params: 590,592
Layer: clinical_bert_model.encoder.layer.6.attention.self.key | Params: 590,592
Layer: clinical_bert_model.encoder.layer.6.attention.self.value | Params: 590,592
Layer: clinical_bert_model.encoder.layer.6.attention.output.dense | Params: 590,592
Layer: clinical_bert_model.encoder.layer.6.attention.output.LayerNorm | Params: 1,536
Layer: clinical_bert_model.encoder.layer.6.intermediate.dense | Params: 2,362,368
Layer: clinical_bert_model.encoder.layer.6.output.dense   | Params: 2,360,064
Layer: clinical_bert_model.encoder.layer.6.output.LayerNorm | Params: 1,536
Layer: clinical_bert_model.encoder.layer.7.attention.self.query | Params: 590,592
Layer: clinical_bert_model.encoder.layer.7.attention.self.key | Params: 590,592
Layer: clinical_bert_model.encoder.layer.7.attention.self.value | Params: 590,592
Layer: clinical_bert_model.encoder.layer.7.attention.output.dense | Params: 590,592
Layer: clinical_bert_model.encoder.layer.7.attention.output.LayerNorm | Params: 1,536
Layer: clinical_bert_model.encoder.layer.7.intermediate.dense | Params: 2,362,368
Layer: clinical_bert_model.encoder.layer.7.output.dense   | Params: 2,360,064
Layer: clinical_bert_model.encoder.layer.7.output.LayerNorm | Params: 1,536
Layer: clinical_bert_model.encoder.layer.8.attention.self.query | Params: 590,592
Layer: clinical_bert_model.encoder.layer.8.attention.self.key | Params: 590,592
Layer: clinical_bert_model.encoder.layer.8.attention.self.value | Params: 590,592
Layer: clinical_bert_model.encoder.layer.8.attention.output.dense | Params: 590,592
Layer: clinical_bert_model.encoder.layer.8.attention.output.LayerNorm | Params: 1,536
Layer: clinical_bert_model.encoder.layer.8.intermediate.dense | Params: 2,362,368
Layer: clinical_bert_model.encoder.layer.8.output.dense   | Params: 2,360,064
Layer: clinical_bert_model.encoder.layer.8.output.LayerNorm | Params: 1,536
Layer: clinical_bert_model.encoder.layer.9.attention.self.query | Params: 590,592
Layer: clinical_bert_model.encoder.layer.9.attention.self.key | Params: 590,592
Layer: clinical_bert_model.encoder.layer.9.attention.self.value | Params: 590,592
Layer: clinical_bert_model.encoder.layer.9.attention.output.dense | Params: 590,592
Layer: clinical_bert_model.encoder.layer.9.attention.output.LayerNorm | Params: 1,536
Layer: clinical_bert_model.encoder.layer.9.intermediate.dense | Params: 2,362,368
Layer: clinical_bert_model.encoder.layer.9.output.dense   | Params: 2,360,064
Layer: clinical_bert_model.encoder.layer.9.output.LayerNorm | Params: 1,536
Layer: clinical_bert_model.encoder.layer.10.attention.self.query | Params: 590,592
Layer: clinical_bert_model.encoder.layer.10.attention.self.key | Params: 590,592
Layer: clinical_bert_model.encoder.layer.10.attention.self.value | Params: 590,592
Layer: clinical_bert_model.encoder.layer.10.attention.output.dense | Params: 590,592
Layer: clinical_bert_model.encoder.layer.10.attention.output.LayerNorm | Params: 1,536
Layer: clinical_bert_model.encoder.layer.10.intermediate.dense | Params: 2,362,368
Layer: clinical_bert_model.encoder.layer.10.output.dense  | Params: 2,360,064
Layer: clinical_bert_model.encoder.layer.10.output.LayerNorm | Params: 1,536
Layer: clinical_bert_model.encoder.layer.11.attention.self.query | Params: 590,592
Layer: clinical_bert_model.encoder.layer.11.attention.self.key | Params: 590,592
Layer: clinical_bert_model.encoder.layer.11.attention.self.value | Params: 590,592
Layer: clinical_bert_model.encoder.layer.11.attention.output.dense | Params: 590,592
Layer: clinical_bert_model.encoder.layer.11.attention.output.LayerNorm | Params: 1,536
Layer: clinical_bert_model.encoder.layer.11.intermediate.dense | Params: 2,362,368
Layer: clinical_bert_model.encoder.layer.11.output.dense  | Params: 2,360,064
Layer: clinical_bert_model.encoder.layer.11.output.LayerNorm | Params: 1,536
Layer: clinical_bert_model.pooler.dense                   | Params: 590,592
Layer: fc_omic.0.0                                        | Params: 1,280,000
Layer: fc_omic.1.0                                        | Params: 65,792
Layer: survival_classifier                                | Params: 5,124
Layer: text_classifier                                    | Params: 1,028
Layer: gene_classifier                                    | Params: 1,028
Layer: lin_weight                                         | Params: 769
Layer: text_projection                                    | Params: 196,864
Layer: gated_fusion_survival                              | Params: 3
Layer: gated_fusion_survival.gate_network.0               | Params: 196,864
Layer: gated_fusion_survival.gate_network.3               | Params: 771
Layer: gated_fusion_survival.fusion_projection.0          | Params: 196,864
Layer: gated_fusion_survival.fusion_projection.3          | Params: 65,792
Layer: gated_fusion_stage                                 | Params: 2
Layer: gated_fusion_stage.gate_network.0                  | Params: 131,328
Layer: gated_fusion_stage.gate_network.3                  | Params: 514
Layer: gated_fusion_stage.fusion_projection.0             | Params: 131,328
Layer: gated_fusion_stage.fusion_projection.3             | Params: 65,792
Done!
Total number of parameters: 111539482
Total number of trainable parameters: 111539482

Init optimizer ... [Config] Using unified lr for text_lr: 5e-05
[Config] Using unified lr for gene_lr: 5e-05
[Learning Rate Config] Unified LR: 5e-05 (Text LR: 5e-05, Gene LR: 5e-05)
[Learning Rate Config] Strategy: Unified

Init Loaders... Done!
üîç [Debug] Detected model.use_debias = False
