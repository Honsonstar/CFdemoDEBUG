#!/usr/bin/env python3
"""
é‡æ–°ç”Ÿæˆæ‰€æœ‰ç™Œç—‡ç±»å‹çš„åµŒå¥—äº¤å‰éªŒè¯åˆ’åˆ†
åŸºäºç”¨æˆ·æä¾›çš„æ¨¡æ¿
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import StratifiedKFold, train_test_split
import os
import argparse

def create_splits(study, n_splits=5, seed=42):
    print(f"\n==========================================")
    print(f"ğŸš€ æ­£åœ¨å¤„ç†ç™Œç§: {study}")
    print(f"==========================================")

    # 1. è·¯å¾„è®¾ç½®
    clinical_file = f"datasets_csv/clinical_data/tcga_{study}_clinical.csv"
    output_dir = f"splits/nested_cv/{study}"
    os.makedirs(output_dir, exist_ok=True)

    if not os.path.exists(clinical_file):
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°æ–‡ä»¶ {clinical_file}")
        return

    # 2. è¯»å–æ•°æ®
    df = pd.read_csv(clinical_file)
    print(f"   åŸå§‹æ ·æœ¬æ•°: {len(df)}")

    # 3. æ¸…æ´—æ•°æ®
    # ä½¿ç”¨ case_id ä½œä¸ºæ ·æœ¬ID
    df = df.dropna(subset=['case_id'])
    # ä½¿ç”¨ censorship ä½œä¸ºåˆ†å±‚æ ‡ç­¾
    df = df.dropna(subset=['censorship'])

    ids = df['case_id'].values
    labels = df['censorship'].values
    print(f"   æœ‰æ•ˆæ ·æœ¬æ•°: {len(ids)}")

    # 4. 5 æŠ˜äº¤å‰éªŒè¯
    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)

    for fold, (train_val_idx, test_idx) in enumerate(skf.split(ids, labels)):
        print(f"\nğŸ”„ ç”Ÿæˆ Fold {fold}...")

        train_val_ids = ids[train_val_idx]
        test_ids = ids[test_idx]
        train_val_labels = labels[train_val_idx]

        # 5. åˆ’åˆ† Train/Val (85% / 15% of Train+Val)
        train_idx, val_idx = train_test_split(
            np.arange(len(train_val_ids)),
            test_size=0.15,
            stratify=train_val_labels,
            random_state=seed
        )

        train_ids = train_val_ids[train_idx]
        val_ids = train_val_ids[val_idx]

        print(f"   âœ“ Train: {len(train_ids)}")
        print(f"   âœ“ Val:   {len(val_ids)}")
        print(f"   âœ“ Test:  {len(test_ids)}")

        # 6. ä¿å­˜ CSV (æ ¼å¼å¯¹é½ nested_cv_wrapper.py)
        max_len = max(len(train_ids), len(val_ids), len(test_ids))

        # å¡«å…… NaN ä»¥å¯¹é½é•¿åº¦
        train_col = list(train_ids) + [np.nan] * (max_len - len(train_ids))
        val_col = list(val_ids) + [np.nan] * (max_len - len(val_ids))
        test_col = list(test_ids) + [np.nan] * (max_len - len(test_ids))

        split_df = pd.DataFrame({
            'train': train_col,
            'val': val_col,
            'test': test_col
        })

        save_path = os.path.join(output_dir, f"nested_splits_{fold}.csv")
        split_df.to_csv(save_path, index=False)
        print(f"   ğŸ’¾ ä¿å­˜è‡³: {save_path}")

    # 7. ç”Ÿæˆæ±‡æ€»æ–‡ä»¶ (Summary)
    summary_data = []
    for fold in range(n_splits):
        f_path = os.path.join(output_dir, f"nested_splits_{fold}.csv")
        if os.path.exists(f_path):
            d = pd.read_csv(f_path)
            summary_data.append({
                'fold': fold,
                'train': d['train'].notna().sum(),
                'val': d['val'].notna().sum(),
                'test': d['test'].notna().sum()
            })
    pd.DataFrame(summary_data).to_csv(os.path.join(output_dir, "summary.csv"), index=False)
    print(f"\nâœ… {study} åˆ’åˆ†å®Œæˆï¼")

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument('--studies', nargs='+',
                        default=['blca', 'brca', 'coadread', 'hnsc', 'stad'],
                        help='è¦å¤„ç†çš„ç™Œç§åˆ—è¡¨')
    parser.add_argument('--seed', type=int, default=42, help='éšæœºç§å­')
    args = parser.parse_args()

    for study in args.studies:
        create_splits(study, seed=args.seed)
