#!/bin/bash
# å¿«é€Ÿåˆ›å»ºåµŒå¥—CVåˆ’åˆ†çš„è„šæœ¬

STUDY=$1
if [ -z "$STUDY" ]; then
    echo "=========================================="
    echo "ç”¨æ³•: bash create_nested_splits.sh <study>"
    echo ""
    echo "å¯ç”¨ç™Œç§:"
    echo "  - blca (è†€èƒ±å°¿è·¯ä¸Šçš®ç™Œ)"
    echo "  - brca (ä¹³è…ºæµ¸æ¶¦ç™Œ)"
    echo "  - hnsc (å¤´é¢ˆé³çŠ¶ç»†èƒç™Œ)"
    echo "  - stad (èƒƒè…ºç™Œ)"
    echo "  - coadread (ç»“ç›´è‚ è…ºç™Œ)"
    echo "=========================================="
    exit 1
fi

echo "=========================================="
echo "åˆ›å»ºåµŒå¥—CVåˆ’åˆ†: $STUDY"
echo "=========================================="

# æ£€æŸ¥ä¸´åºŠæ•°æ®æ–‡ä»¶
CLINICAL_FILE="datasets_csv/clinical_data/tcga_${STUDY}_clinical.csv"
if [ ! -f "$CLINICAL_FILE" ]; then
    echo "âŒ é”™è¯¯: æ‰¾ä¸åˆ°ä¸´åºŠæ•°æ®æ–‡ä»¶ $CLINICAL_FILE"
    exit 1
fi

# åˆ›å»ºè¾“å‡ºç›®å½•
OUTPUT_DIR="splits/nested_cv/${STUDY}"
mkdir -p "$OUTPUT_DIR"

# è¿è¡ŒPythonè„šæœ¬åˆ›å»ºåˆ’åˆ†
python3 << PYTHON
import pandas as pd
import numpy as np
from sklearn.model_selection import StratifiedKFold, train_test_split
import os

print("\nğŸ“Š å¼€å§‹åˆ›å»ºåµŒå¥—CVåˆ’åˆ†...")
print(f"   ç™Œç§: $STUDY")
print(f"   è¾“å…¥æ–‡ä»¶: $CLINICAL_FILE")
print(f"   è¾“å‡ºç›®å½•: $OUTPUT_DIR")

# è¯»å–æ•°æ®
df = pd.read_csv('$CLINICAL_FILE')
print(f"   æ€»æ ·æœ¬æ•°: {len(df)}")

# æ¸…ç†æ•°æ®
df = df.dropna(subset=['case_id', 'censorship'])
df = df[df['case_id'].astype(bool)]
print(f"   æ¸…æ´—åæ ·æœ¬æ•°: {len(df)}")

# è·å–IDå’Œæ ‡ç­¾
ids = df['case_id'].values
labels = df['censorship'].values

print(f"   æœ‰æ•ˆæ ·æœ¬æ•°: {len(ids)}")

# 5æŠ˜äº¤å‰éªŒè¯
skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

for fold in range(5):
    print(f"\nğŸ”„ å¤„ç† Fold {fold}...")

    train_val_idx, test_idx = next(skf.split(ids, labels))
    train_val_ids = ids[train_val_idx]
    test_ids = ids[test_idx]
    train_val_labels = labels[train_val_idx]

    # åˆ’åˆ†è®­ç»ƒ/éªŒè¯ (85% / 15%)
    train_idx, val_idx = train_test_split(
        np.arange(len(train_val_ids)),
        test_size=0.15,
        stratify=train_val_labels,
        random_state=42
    )

    train_ids = train_val_ids[train_idx]
    val_ids = train_val_ids[val_idx]

    print(f"   âœ“ Train: {len(train_ids):3d} æ ·æœ¬")
    print(f"   âœ“ Val:   {len(val_ids):3d} æ ·æœ¬")
    print(f"   âœ“ Test:  {len(test_ids):3d} æ ·æœ¬")

    # ç›´æ¥ä¿å­˜ä¸ºCSVï¼Œä¸ä½¿ç”¨DataFrame
    output_file = f'$OUTPUT_DIR/nested_splits_{fold}.csv'
    with open(output_file, 'w') as f:
        f.write('train,val,test\n')
        max_len = max(len(train_ids), len(val_ids), len(test_ids))
        for i in range(max_len):
            train = str(train_ids[i]) if i < len(train_ids) else ''
            val = str(val_ids[i]) if i < len(val_ids) else ''
            test = str(test_ids[i]) if i < len(test_ids) else ''
            f.write(f'{train},{val},{test}\n')

    print(f"   â†’ ä¿å­˜åˆ°: {output_file}")

# ä¿å­˜æ±‡æ€»ä¿¡æ¯
summary = []
for fold in range(5):
    output_file = f'$OUTPUT_DIR/nested_splits_{fold}.csv'
    if os.path.exists(output_file):
        # åªè¯»å–æœ‰æ•°æ®çš„è¡Œ
        df_split = pd.read_csv(output_file, skip_blank_lines=True)
        # åˆ é™¤ç©ºè¡Œ
        df_split = df_split.dropna(how='all')
        summary.append({
            'fold': fold,
            'train': len(df_split['train'].dropna()),
            'val': len(df_split['val'].dropna()),
            'test': len(df_split['test'].dropna())
        })

if summary:
    summary_df = pd.DataFrame(summary)
    summary_df.to_csv(f'$OUTPUT_DIR/summary.csv', index=False)

    print("\n" + "="*50)
    print("âœ… åµŒå¥—CVåˆ’åˆ†åˆ›å»ºå®Œæˆ!")
    print("="*50)
    print(f"\nğŸ“ è¾“å‡ºç›®å½•: $OUTPUT_DIR")
    print(f"ğŸ“„ æ–‡ä»¶åˆ—è¡¨:")
    for fold in range(5):
        print(f"   - nested_splits_{fold}.csv")
    print(f"   - summary.csv")

    print(f"\nğŸ“Š æ±‡æ€»ä¿¡æ¯:")
    print(summary_df.to_string(index=False))
else:
    print("\nâŒ é”™è¯¯: æœªèƒ½ç”Ÿæˆä»»ä½•åˆ’åˆ†æ–‡ä»¶")

PYTHON

echo ""
echo "=========================================="
echo "è„šæœ¬æ‰§è¡Œå®Œæˆ!"
echo "=========================================="
